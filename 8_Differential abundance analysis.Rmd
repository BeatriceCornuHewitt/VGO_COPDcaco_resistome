# Differential abundance analysis 
# Preparing PS object for DA analysis - unfiltered 
```{r}
# Since the DA analyses require count data which has not been corrected for gene length, I need to create a new ps object with only corrections for volume input and qPCR bacterial count
PS_rarefied <- readRDS("Output_files//Phyloseq_objects//2_COPD_resistome_phyloseq_object_rarefied.RDS") 
# convert otu fpk values directly by matrix manipulation in the ps object using qPCRcounts data frame 
PS_rarefied.16Scorrected <- PS_rarefied
PS_rarefied.16Scorrected@otu_table@.Data <- PS_rarefied.16Scorrected@otu_table@.Data / qPCRcounts[1:73, ]

# check PS 
PS_rarefied.16Scorrected
head(taxa_names(PS_rarefied.16Scorrected))

## Remove duplicate sample (13674) from the dataset
Final.ps.DAanalysis.unclustered <- prune_samples(sample_names(PS_rarefied.16Scorrected) != "13674", PS_rarefied.16Scorrected) 
# Final PS object therefore now has 72 samples in total (35 cases, 34 controls, 3 blanks)

# This is the ps object to be used for DA analysis (not gene length corrected but corrected for input volumes and qPCR bacterial counts). 
# Now need to cluster at the 90% identity level 

# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
Final.ps.DAanalysis <- tax_glom2(Final.ps.DAanalysis.unclustered, taxrank=rank_names(Final.ps.DAanalysis.unclustered)[6], NArm=TRUE)
taxa_names(Final.ps.DAanalysis)
# Taxa names are not correct
tax_table(Final.ps.DAanalysis)
taxa_names(Final.ps.DAanalysis)
otu_table(Final.ps.DAanalysis)

# Save normalised & 16S qPCR-corrected PS object ready for DA analysis input
saveRDS(Final.ps.DAanalysis, "Output_files//Phyloseq_objects//7_COPD_resistome_phyloseq_object_rarefied_16SqPCRcorrected.RDS")

# Rename ARGs to their cluster name
Final.ps.DAanalysis.clusternames <- Final.ps.DAanalysis
colnames(Final.ps.DAanalysis.clusternames@otu_table) <- c("aac(3)-II_clust","aac(3)-Iva","aac(6')-aph(2'')_clust","aadA_ant(3'')-Ia_clust","aadA_clust1","aadD","ant(6)-Ia_clust2","aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(3')-Ib","aph(3')-III","aph(4)-Ia","aph(6)-Id","str","blaACT_clust","blaACT_CMG_MIR_clust","blaBRO","blaCARB_clust2","blaCTX-M_clust1","blaOXA-22","blaOXA-395_clust","blaOXA-60_clust","blaOXA-85","blaOXA_clust19","blaOXA_clust3","blaOXA_clust8","blaOXA_clust9","blaOXY_clust1","blaSPU-1","blaTEM_clust","blaZ_clust","cfxA_clust","mecA_clust","mecA1","penA","fusB","lsa(A)","lsa(C)","erm(A)_2_AF002716","erm(B)_clust","erm(C)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","lnu(C)","mdf(A)","mef(A)-3","mef(A)_clust","mph(A)","mph(C)","msr(A)","msr(D)","msr(E)","vga(A)_clust","cat(pC194)","cat_2","catA1","catQ","catS","cml_clust","cmx","cfr(C)","sul1","sul2","tet(32)","tet(33)","tet(37)","tet(39)","tet(40)","tet(44)","tet(A)","tet(B)","tet(C)","tet(G)","tet(K)","tet(L)_clust1","tet(M)","tet(O)","tet(O/32/O)","tet(O/W/32/O/W/O)","tet(O/W/O)-1","tet(Q)","tet(T)","tet(W)","dfrA15_clust")

saveRDS(Final.ps.DAanalysis.clusternames, "Output_files//Phyloseq_objects//8_COPD_resistome_phyloseq_object_rarefied_16SqPCRcorrected_clusternames.RDS")

# Remove blanks from PS object 
blanks <- subset_samples(Final.ps.DAanalysis.clusternames@sam_data, copdcaco == "blanc")
# Convert 'blanks' to a character vector of sample names
blank_names <- as.character(sample_names(blanks))
# Prune samples from 'ARGcluster.aggl'
Final.ps.DAanalysis.clusternames.noblanks <- Final.ps.DAanalysis.clusternames
Final.ps.DAanalysis.clusternames.noblanks <- prune_samples(!sample_names(Final.ps.DAanalysis.clusternames.noblanks)%in%blank_names, Final.ps.DAanalysis.clusternames.noblanks)
Final.ps.DAanalysis.clusternames.noblanks
```
# Preparing PS object for DA analysis - filtered 
```{r}
# Copy over ps object to be used
Final.ps.DAanalysis.filtered <- Final.ps.DAanalysis

# Remove blanks from PS object 
blanks <- subset_samples(Final.ps.DAanalysis.filtered@sam_data, copdcaco == "blanc")
# Convert 'blanks' to a character vector of sample names
blank_names <- as.character(sample_names(blanks))
# Prune samples from 'ARGcluster.aggl'
Final.ps.DAanalysis.filtered.noblanks <- Final.ps.DAanalysis.filtered
Final.ps.DAanalysis.filtered.noblanks <- prune_samples(!sample_names(Final.ps.DAanalysis.filtered.noblanks)%in%blank_names, Final.ps.DAanalysis.filtered.noblanks)

# Create prevalence-abundance filter
# 0.1% abundant, 15% prevalent:  
pres_abund_filter_DAanalysis <- function(Final.ps.DAanalysis.filtered.noblanks, pres=10.35, abund=0.001) { # Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
filter_taxa(Final.ps.DAanalysis.filtered.noblanks, function(x) sum(x >= abund)>=pres, TRUE) }
# apply filter
Final.ps.DAanalysis.filtered.noblanks <- transform_sample_counts(Final.ps.DAanalysis.filtered.noblanks, function(x) x/sum(x) *100 ) %>% pres_abund_filter_DAanalysis()
# Now there are 30 taxa (instead of 85)

# Now rename to actual cluster names
taxa_names(Final.ps.DAanalysis.filtered.noblanks)

colnames(Final.ps.DAanalysis.filtered.noblanks@otu_table) <- c("aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(4)-Ia","aph(6)-Id","blaOXA-60_clust","blaSPU-1","blaTEM_clust","cfxA_clust","penA","lsa(C)","erm(B)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","mef(A)-3","mef(A)_clust","msr(D)","cat(pC194)","sul1","sul2","tet(32)","tet(37)","tet(A)","tet(B)","tet(C)","tet(M)","tet(O)","tet(O/W/32/O/W/O)","tet(Q)","tet(W)")
```
# Heatmap to check distribution of ARG clusters post filtering
```{r}
# Create a heatmap now on the cluster 90 level as this is a better representation of the data 
# Extract abundance matrix from cluster 90 agglomerated ps object
ARGclustertable.filtered <- as(otu_table(Final.ps.DAanalysis.filtered.noblanks), "matrix")
# transform into a data frame
ARGcluster.filtered.dataframe <- as.data.frame(ARGclustertable.filtered)
ARGcluster.filtered.dataframe
# Examine actual cluster 90 names and names assigned in the ps object
Final.ps.DAanalysis.filtered.noblanks@tax_table[,6]

# column names are (specific) ARG names, agglomeration is correct (lowest level is ARG cluster) but col names are not correct - I will rename the column names to the AMR classes for presentation in the heatmap
colnames(ARGcluster.filtered.dataframe) <- c("aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(4)-Ia","aph(6)-Id","blaOXA-60_clust","blaSPU-1","blaTEM_clust","cfxA_clust","penA","lsa(C)","erm(B)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","mef(A)-3","mef(A)_clust","msr(D)","cat(pC194)","sul1","sul2","tet(32)","tet(37)","tet(A)","tet(B)","tet(C)","tet(M)","tet(O)","tet(O/W/32/O/W/O)","tet(Q)","tet(W)")

# Check the renaming has been performed correctly
colnames(ARGcluster.filtered.dataframe)

# transform the raw counts of reads to proportions of total ARG clusters in each sample 
ARGcluster.filtered.dataframe.prop <- ARGcluster.filtered.dataframe/rowSums(ARGcluster.filtered.dataframe)
# Examine the dataframe 
ARGcluster.filtered.dataframe.prop

# calculate the Bray-Curtis dissimilarity matrix on the full dataset
ARGCluster.filtered.BCdist <- vegdist(ARGcluster.filtered.dataframe.prop, method = "bray")

# perform hierarchical cluster analysis using the BC dissimilarities 
# each sample is assigned to its own cluster and then the algorithm proceeds iteratively, at each stage joining the two most similar clusters, continuing until there is just a single cluster.
ARGCluster.hierarchicalclust <- hclust(ARGCluster.filtered.BCdist, "aver")

# Create a heatmap at the ARG cluster level
COPDcontrolblank <- Final.ps.DAanalysis.filtered.noblanks@sam_data$copdcaco 
COPDcontrolblank<- replace(COPDcontrolblank, which(COPDcontrolblank == "0"), "blue")
COPDcontrolblank<-replace(COPDcontrolblank, which(COPDcontrolblank == "1"), "red")
COPDcontrolblank # check that colours are allocated to the groups

heatmap.ARGClusterlevel <- heatmap(
  as.matrix(ARGcluster.filtered.dataframe.prop),
  Rowv = as.dendrogram(ARGCluster.hierarchicalclust),
  RowSideColors = COPDcontrolblank,
  margins = c(11, 5),
  xlab = "ARGCluster",
  ylab = "SampleIDs",
  main = "Hierarchical clustering heatmap at 90% ARG cluster level",
  las = 2,  # Set label orientation to horizontal
  cexRow = 0.8,
  cexCol = 0.5# Adjust the font size of the row labels
)
# Note that the samples are not in the same order as that in the matrix - heatmap() reorders both variables and observations using the BC clustering algorithm: it computes the distance between each pair of rows and columns and try to order them by similarity.

```
# DESeq2 analysis
## DESeq2 on unfiltered data
```{r}
# Using WvK method - with phyloseq_to_deseq2 function
phyloseq_to_deseq2_obj_unfiltered <- phyloseq_to_deseq2(Final.ps.DAanalysis.clusternames.noblanks,~copdcaco)

# RUN DESeq function 
phyloseq_to_deseq2_obj_unfiltered <- DESeq(phyloseq_to_deseq2_obj_unfiltered)
deseq2_results_unfiltered <- results(phyloseq_to_deseq2_obj_unfiltered)
deseq2_results_unfiltered

# summary of differential gene expression
summary(deseq2_results_unfiltered)
head(deseq2_results_unfiltered)

# Information about which variables and tests were used for the results is given by this function
mcols(deseq2_results_unfiltered)$description

# Order the results table by the smallest p value:
deseq2_results_unfiltered_ordered <- deseq2_results_unfiltered[order(deseq2_results_unfiltered),]
deseq2_results_unfiltered_ordered #tet(K)_1_U38656 has the greatest difference between COPD and controls

# How many adjusted p-values are < 0.1? 
sum(deseq2_results_unfiltered$padj < 0.1, na.rm=TRUE) # 0 ARG clusters are <0.1

# Create dispersion estimate plot
plotDispEsts(phyloseq_to_deseq2_obj_unfiltered)


# CONTINUE FROM HERE MONDAY
# we can use plotCounts fxn to compare the normalized counts between COPD and control groups for our top 4 ARGs
par(mfrow=c(1,2))
plotCounts(dds_method2, gene="msr(D)_3_AF227520", intgroup="copdcaco")
plotCounts(dds_method2, gene="tet(M)_4_X75073", intgroup="copdcaco")

# Plot to show the log2 fold changes attributable to a given variable over the mean of normalized counts for all the samples in the DESeqDataSet. Points will be colored red if the adjusted p value is less than 0.1. Points which fall out of the window are plotted as open triangles pointing either up or down.
plotMA(res_method2, ylim=c(-2,2), size= 20)

# Shrink the log2fold changes as these provide better LFC estimates
resultsNames(dds_method2)
BiocManager::install("apeglm")
resLFCshrink <- lfcShrink(dds_method2, coef="copdcaco_1_vs_0", type="apeglm")
resLFCshrink

#It is more useful visualize the MA-plot for the shrunken log2 fold changes, which remove the noise associated with log2 fold changes from low count genes without requiring arbitrary filtering thresholds.
plotMA(resLFCshrink, ylim=c(-2,2)) # plot looks odd...?

# Using ggplot2 to create an MA plot
# Load libraries
# install.packages(c("ggplot2", "scales", "viridis"))
library(ggplot2)
library(scales) # needed for oob parameter
library(viridis)
# Coerce to a data frame
deseq2ResDF <- as.data.frame(res_method2)
# Examine this data frame
head(deseq2ResDF)
# Set a boolean column for significance
deseq2ResDF$significant <- ifelse(deseq2ResDF$padj < .1, "Significant", NA)
# Plot the results similar to DEseq2
ggplot(deseq2ResDF, aes(baseMean, log2FoldChange, colour=significant)) + geom_point(size=1) + scale_y_continuous(limits=c(-3, 3), oob=squish) + scale_x_log10() + geom_hline(yintercept = 0, colour="tomato1", size=2) + labs(x="mean of normalized counts", y="log fold change") + scale_colour_manual(name="q-value", values=("Significant"="red"), na.value="grey50") + theme_bw()
# Let's add some more detail
ggplot(deseq2ResDF, aes(baseMean, log2FoldChange, colour=padj)) + geom_point(size=1) + scale_y_continuous(limits=c(-3, 3), oob=squish) + scale_x_log10() + geom_hline(yintercept = 0, colour="darkorchid4", size=1, linetype="longdash") + labs(x="mean of normalized counts", y="log fold change") + scale_colour_viridis(direction=-1, trans='sqrt') + theme_bw() + geom_density_2d(colour="black", size=2)

# volcano plot
#reset par
par(mfrow=c(1,1))
# Make a basic volcano plot
with(res_method2, plot(log2FoldChange, -log10(pvalue), pch=20, main="Volcano plot", xlim=c(-3,3)))

# Add colored points: blue if padj<0.01, red if log2FC>1 and padj<0.05)
with(res_method2, plot(log2FoldChange, -log10(pvalue), pch=20, main="Volcano plot", xlim=c(-3,3)))
with(subset(res_method2, padj<.1 ), points(log2FoldChange, -log10(pvalue), pch=20, col="red"))

```
## DESeq2 on filtered data (0.1% relative abundance, 15% prevalent) 
```{r}
# Now run DESeq analysis again with this newly filtered data on COPD status 
Final.ps.DAanalysis.filtered.noblanks@sam_data$copdcaco
# Convert copdcaco column to factor variable (from character)
Final.ps.DAanalysis.filtered.noblanks@sam_data$copdcaco <- as.factor(Final.ps.DAanalysis.filtered.noblanks@sam_data$copdcaco)

deseq2.copd.filt <- phyloseq_to_deseq2(Final.ps.DAanalysis.filtered.noblanks, ~copdcaco)
head(deseq2.copd.filt)

# N.B when we use phyloseq_to_deseq2, it converts all counts into integers, therefore for some ARGs whihc only have counts < 0.1, these all become zero, and therefore BaseMean = 0 and log2 fold changes are NA - there 

# RUN  DESeq function 
deseq2.copd.filt <- DESeq(deseq2.copd.filt, parallel = FALSE)
deseq2.copd.results.filt <- results(deseq2.copd.filt)
deseq2.copd.results.filt
deseq2.copd.results.filt.df <- as.data.frame(deseq2.copd.results.filt)
write.xlsx(deseq2.copd.results.filt.df, "Output_files//Differential_abundance//DESeq_results_table.xlsx", row.names = TRUE)


#summary of differential gene expression
summary(deseq2.copd.results.filt)
head(deseq2.copd.results.filt)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2.copd.results.filt)$description
# Order the results table by the smallest p value:
deseq2.copd.results.filt.ordered <- deseq2.copd.results.filt[order(deseq2.copd.results.filt$pvalue),]
deseq2.copd.results.filt.ordered 
sum(deseq2.copd.results.filt.ordered$padj < 0.05, na.rm=TRUE) # I now find 1 ARG cluster which has a p-value of <0.1

# Produce horizontal bar plots 
data_DESEq2 <- data.frame(
  ARGCluster = rownames(deseq2.copd.results.filt),
  LogFoldChange = deseq2.copd.results.filt$log2FoldChange,
  StandardError = deseq2.copd.results.filt$lfcSE,
  AdjustedPval = deseq2.copd.results.filt$padj
)

# Filter out rows with NA LogFoldChange - some of these are NA because DESeq can only deal with integers, so any ARGs that have abundances < 1 have an overall BaseMean of 0 and therefore do not have a corresponding log2 fold change
data_DESEq2 <- data_DESEq2[complete.cases(data_DESEq2), ]

# Determine the fill color based on the sign of LogFoldChange
data_DESEq2$FillColor <- ifelse(data_DESEq2$LogFoldChange > 0, "darkorange", "cornflowerblue")
data_DESEq2$ARGCluster <- reorder(data_DESEq2$ARGCluster, data_DESEq2$LogFoldChange)

# Create the horizontal bar plot - with p values (not adjusted)
DESeq2_barplot <- ggplot(data_DESEq2, aes(y = ARGCluster, x = LogFoldChange, fill = FillColor)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbarh(aes(xmin = LogFoldChange - StandardError, xmax = LogFoldChange + StandardError), height = 0.2) +
  scale_fill_identity() +  # Set fill color to FillColor
  labs(y = "ARG Cluster", x = "Log2 Fold Change") +
  theme_minimal() + # You can customize the theme as needed
  theme(
    panel.background = element_rect(fill = "white"),  # Set the background to white
    plot.background = element_rect(fill = "white")     # Set the plot area background to white
  )

# Show the plot
print(DESeq2_barplot)
ggsave("Output_files//Differential_abundance//horizontal_DESeq2_bar_plot.png", plot = DESeq2_barplot, width = 8, height = 10, units = "in", dpi = 1000)


# # create plot - from mol epi course - see DADA2 practical
# Plot to show the log2 fold changes attributable to a given variable over the mean of normalized counts for all the samples in the DESeqDataSet. Points will be colored red if the adjusted p value is less than 0.1. Points which fall out of the window are plotted as open triangles pointing either up or down.
plotMA(deseq2.copd.results.filt.ordered, ylim=c(-2,2))

# Shrink the log2fold changes as these provide better LFC estimates
resultsNames(deseq2.exp.DISP_EUinPM10_AnnualAv_WP99.5.cont)
BiocManager::install("apeglm")
library(apeglm)
resultsNames(deseq2.copd.filt)
deseq2.copd.filt.lfcshrink <- lfcShrink(deseq2.copd.filt, coef="copdcaco_1_vs_0", type="apeglm")
deseq2.copd.filt.lfcshrink
#It is more useful visualize the MA-plot for the shrunken log2 fold changes, which remove the noise associated with log2 fold changes from low count genes without requiring arbitrary filtering thresholds.
plotMA(deseq2.copd.results.filt, ylim=c(-2,2)) # plot looks odd...?

# Using ggplot2 to create an MA plot
# Load libraries
# install.packages(c("ggplot2", "scales", "viridis"))
library(ggplot2)
library(scales) # needed for oob parameter
library(viridis)
# Coerce to a data frame
deseq2.copd.results.filt.copdcaco.MAplot <- as.data.frame(deseq2.copd.results.filt)
# Examine this data frame
head(deseq2.copd.results.filt.copdcaco.MAplot)
# Set a boolean column for significance
deseq2.copd.results.filt.copdcaco.MAplot$significant <- ifelse(deseq2.copd.results.filt.copdcaco.MAplot$padj < .05, "Significant", NA)
# Plot the results in an MA plot 
ggplot(deseq2.copd.results.filt.copdcaco.MAplot, aes(baseMean, log2FoldChange, colour=significant)) + geom_point(size=3) + scale_y_continuous(limits=c(-2, 2)) + scale_x_log10() + geom_hline(yintercept = 0, colour="red", size=0.5) + labs(x="Mean of ARG counts", y="Log2 fold change - COPD case to control") +  scale_colour_manual(name="q-value", values=("Significant"="red"), na.value="black") + theme_bw()

# Create a plot of counts 
deseq2.copd.results.filt.ordered[1,]
rowname(deseq2.copd.results.filt.ordered[1,]) <- ""

plotCounts(deseq2.copd.filt, gene=which.min(deseq2.copd.results.filt$padj), intgroup="copdcaco", xlab = "Control (0) vs COPD case (1)")
```
# ALDEx2 
## ALDEx2 on unfiltered data
```{r}
# 
BiocManager::install("ALDEx2")
library(ALDEx2)

Countdata.DESeq2 # This is the ps object to be used for ALDex2 analysis (not gene length corrected but corrected for input volumes and qPCR bacterial counts). BUT this is not at the 90% cluster level so I should agglomerate this ps object (using previously created tax_glom2 function from AB - see below too)
# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
ARGcluster.aggl.ALDEx2 <- tax_glom2(Countdata.DESeq2, taxrank=rank_names(Countdata.DESeq2)[6], NArm=TRUE)
taxa_names(ARGcluster.aggl.ALDEx2)
# Confused why the 'taxa_names' are not the arg cluster names? AB responded saying: "What you see is perfectly normal. If you checkout the tax_table you will see that the lowest level is cluster. The lower ranks should be NA. That is why you use explaining Ps object names to realise some aggregation happened. The data is underneath still linked on indiv accno level but incomplete. Only one per arg cluster should be present.  If you now directly ask the taxon name it is indeed "wrong" the accession name. Just use the arg cluster name corresponding to it and you should be fine. Most functions suited for Ps object allow to mention the tax rank or the fill rank to use. They handle it for you underneath in the same way.No worries, just check above and if that matches. Just continue and be sure to use the name of the tax rank. 
# Check tax-table of ps object
tax_table(ARGcluster.aggl.ALDEx2)

# How many taxa before/after agglomeration?
ntaxa(Countdata.DESeq2); ntaxa(ARGcluster.aggl.ALDEx2)
# 85 ARGClusters vs 233 ARGs 

#Rename ARG clusters by cluster name
colnames(ARGcluster.aggl.ALDEx2@otu_table) <- c("aac(3)-II_clust","aac(3)-Iva","aac(6')-aph(2'')_clust","aadA_ant(3'')-Ia_clust","aadA_clust1","aadD","ant(6)-Ia_clust2","aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(3')-Ib","aph(3')-III","aph(4)-Ia","aph(6)-Id","str","blaACT_clust","blaACT_CMG_MIR_clust","blaBRO","blaCARB_clust2","blaCTX-M_clust1","blaOXA-22","blaOXA-395_clust","blaOXA-60_clust","blaOXA-85","blaOXA_clust19","blaOXA_clust3","blaOXA_clust8","blaOXA_clust9","blaOXY_clust1","blaSPU-1","blaTEM_clust","blaZ_clust","cfxA_clust","mecA_clust","mecA1","penA","fusB","lsa(A)","lsa(C)","erm(A)_2_AF002716","erm(B)_clust","erm(C)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","lnu(C)","mdf(A)","mef(A)-3","mef(A)_clust","mph(A)","mph(C)","msr(A)","msr(D)","msr(E)","vga(A)_clust","cat(pC194)","cat_2","catA1","catQ","catS","cml_clust","cmx","cfr(C)","sul1","sul2","tet(32)","tet(33)","tet(37)","tet(39)","tet(40)","tet(44)","tet(A)","tet(B)","tet(C)","tet(G)","tet(K)","tet(L)_clust1","tet(M)","tet(O)","tet(O/32/O)","tet(O/W/32/O/W/O)","tet(O/W/O)-1","tet(Q)","tet(T)","tet(W)","dfrA15_clust")

# create otu table for aldex2 analysis - this needs to be "A non-negative, integer-only data.frame or matrix with unique names for all rows and columns. Rows should contain genes and columns should contain sequencing read counts (i.e., sample vectors). Rows with 0 reads in each sample are deleted prior to analysis
ALDEx2.otutable.trans <- t(otu_table(ARGcluster.aggl.ALDEx2))
ALDEx2.otutable.trans.bill.round <- round(ALDEx2.otutable.trans * 1000000000,0) # I multiply by billion as aldex2 requires that reads are all integers 
otutab.for.ALDEx2 <- data.frame(ALDEx2.otutable.trans.bill.round)
# Then we set the comparison groups. This must be a vector of conditions in the same order as the samples in the input counts table.
sampledata.for.ALDEx2 <- sample_data(ARGcluster.aggl.ALDEx2)$copdcaco

# Run the aldex command - I ask aldex to do a 2-sample t-test to calculate effect sizes,
# The aldex function is a wrapper that performs log-ratio transformation and statistical testing in a single line of code. Specifically, this function: (a) generates Monte Carlo samples of the Dirichlet distribution for each sample, (b) converts each instance using a log-ratio transform, then (c) returns test results for two sample (Welch’s t, Wilcoxon) or multi-sample (glm, Kruskal-Wallace) tests. This function also estimates effect size for two sample analyses.
ALDEx2_COPDcontrol <- ALDEx2::aldex(otutab.for.ALDEx2, sampledata.for.ALDEx2, test="t", effect = TRUE, denom="iqlr")  # Aldex parameters set: test = "t" runs Welch's t-test and Wilcoxon tests. Effect = TRUE - tells aldex to calculate effect sizes. Denom="iqlr" is commonly used and indicates which features to retain as the denominator for the geometric mean calculation - "iqlr" accounts for data with systematic variation.

# Create MA and Effect plots of ALDEx2 output
# create Bland-Altman plot 
par(mfrow = c(1, 2))
aldex.plot(ALDEx2_COPDcontrol, type="MA", test="welch", xlab="Log-ratio abundance",
    ylab="Difference")
# create variance-difference plot 
aldex.plot(ALDEx2_COPDcontrol, type="MW", test="welch", xlab="Dispersion",
    ylab="Difference", all.cex = 3)

# Compute an aldex.clr object
ALDEx2_COPDcontrol.clr <- aldex.clr(otutab.for.ALDEx2, sampledata.for.ALDEx2, mc.samples=16, denom="all", verbose=F)
# aldex.ttest calculates the expected values of the Wilcoxon Rank Sum test and Welch’s t-test on the data returned by aldex.clr.
ALDEx2_COPDcontrol.tt <- aldex.ttest(ALDEx2_COPDcontrol.clr, paired.test=FALSE, verbose=FALSE)
ALDEx2_COPDcontrol.tt 
# where: we.ep - Expected P value of Welch’s t test, we.eBH - Expected Benjamini-Hochberg corrected P value of Welch’s t test, wi.ep - Expected P value of Wilcoxon rank test, wi.eBH - Expected Benjamini-Hochberg corrected P value of Wilcoxon test
# I will look at Wilcoxon test results with BH correction (we.eBH)
# Reorder the p-values based on size of wi.eBH value
reOrdered_ALDEx2_COPDcontrol.tt <- ALDEx2_COPDcontrol.tt[order(ALDEx2_COPDcontrol.tt$wi.eBH),]
reOrdered_ALDEx2_COPDcontrol.tt
# check to identify how many values are significant from the t-test (q<0.1)
which(ALDEx2_COPDcontrol.tt$wi.eBH < 0.1)
# No clusters have BH corrected p-value < 0.1
# Therefore we conclude that using the ALDEx2 method, we do not identify any ARGs which are differentially abundant. 
# Estimate effect size and the within and between condition values in the case of two conditions
ALDEx2_COPDcontrol.effect <- aldex.effect(ALDEx2_COPDcontrol.clr, CI=T, verbose=FALSE)
# Merging the t-test and effect data are merged into one object
ALDEx2_COPDcontrol.all <- data.frame(ALDEx2_COPDcontrol.tt,ALDEx2_COPDcontrol.effect)
```
## ALDEx2 on filtered data (0.1% relative abundance, 15% prevalent)
```{r}
BiocManager::install("ALDEx2")
library(ALDEx2)

# copy over the previously agglomerated and filtered ps object from my above DESeq2 analysis
ARGcluster.aggl.ALDEx2.filtered <- ARGcluster.aggl.DESeq2.filtered.relative
ARGcluster.aggl.ALDEx2.filtered
tax_table(ARGcluster.aggl.ALDEx2.filtered)
# 30 ARG Clusters 

# create otu table for aldex2 analysis - this needs to be "A non-negative, integer-only data.frame or matrix with unique names for all rows and columns. Rows should contain genes and columns should contain sequencing read counts (i.e., sample vectors). Rows with 0 reads in each sample are deleted prior to analysis
ALDEx2.filtered.otutable.trans <- t(otu_table(ARGcluster.aggl.ALDEx2.filtered))
ALDEx2.filtered.otutable.trans.bill.round <- round(ALDEx2.filtered.otutable.trans * 1000000000,0) # I multiply by billion as aldex2 requires that reads are all integers 
otutab.for.ALDEx2.filtered <- data.frame(ALDEx2.filtered.otutable.trans.bill.round)
# Then we set the comparison groups. This must be a vector of conditions in the same order as the samples in the input counts table.
sampledata.for.ALDEx2 <- sample_data(ARGcluster.aggl.ALDEx2.filtered)$copdcaco

# Run the aldex command - I ask aldex to do a 2-sample t-test to calculate effect sizes,
# The aldex function is a wrapper that performs log-ratio transformation and statistical testing in a single line of code. Specifically, this function: (a) generates Monte Carlo samples of the Dirichlet distribution for each sample, (b) converts each instance using a log-ratio transform, then (c) returns test results for two sample (Welch’s t, Wilcoxon) or multi-sample (glm, Kruskal-Wallace) tests. This function also estimates effect size for two sample analyses.
ALDEx2.filtered.COPDcontrol <- ALDEx2::aldex(otutab.for.ALDEx2.filtered, sampledata.for.ALDEx2, test="t", effect = TRUE, denom="iqlr", include.sample.summary = TRUE) # Aldex parameters set: test = "t" runs Welch's t-test and Wilcoxon tests. Effect = TRUE - tells aldex to calculate effect sizes. Denom="iqlr" is commonly used and indicates which features to retain as the denominator for the geometric mean calculation - "iqlr" accounts for data with systematic variation. 
ALDEx2.filtered.COPDcontrol

# Create MA and Effect plots of ALDEx2 output
# create Bland-Altman plot 
par(mfrow = c(1, 2))
aldex.plot(ALDEx2_COPDcontrol, type="MA", test="welch", xlab="Log-ratio abundance",
    ylab="Difference")
# create variance-difference plot 
aldex.plot(ALDEx2_COPDcontrol, type="MW", test="welch", xlab="Dispersion",
    ylab="Difference", all.cex = 3)

# Compute an aldex.clr object
ALDEx2.filtered.COPDcontrol.clr <- aldex.clr(otutab.for.ALDEx2.filtered, sampledata.for.ALDEx2, mc.samples=128, denom="all", verbose=F)
# aldex.ttest calculates the expected values of the Wilcoxon Rank Sum test and Welch’s t-test on the data returned by aldex.clr.
ALDEx2.filtered.COPDcontrol.ttest <- aldex.ttest(ALDEx2.filtered.COPDcontrol.clr, paired.test=FALSE, verbose=FALSE)
ALDEx2.filtered.COPDcontrol.ttest 
# where: we.ep - Expected P value of Welch’s t test, we.eBH - Expected Benjamini-Hochberg corrected P value of Welch’s t test, wi.ep - Expected P value of Wilcoxon rank test, wi.eBH - Expected Benjamini-Hochberg corrected P value of Wilcoxon test
# I will look at Wilcoxon test results with BH correction (we.eBH)
# Reorder the p-values based on size of wi.eBH value
reOrdered_ALDEx2.filtered.COPDcontrol.ttest <- ALDEx2.filtered.COPDcontrol.ttest[order(ALDEx2.filtered.COPDcontrol.ttest$wi.eBH),]
reOrdered_ALDEx2.filtered.COPDcontrol.ttest
# check to identify how many values are significant from the t-test (q<0.1)
which(ALDEx2.filtered.COPDcontrol.ttest$wi.eBH < 0.1)
# 0 ARG clusters are differentially abundant 
# Therefore we conclude that using the ALDEx2 method, we do not identify any ARGs which are differentially abundant

# Estimate effect size and the within and between condition values in the case of two conditions
ALDEx2.filtered.COPDcontrol.effect <- aldex.effect(ALDEx2.filtered.COPDcontrol.clr, CI=T, verbose=FALSE)
```
# ANCOM-BC2
## ANCOM-BC2 on filtered data (0.1% relative abundance, 15% prevalent)
```{r}
# Subset the tax_table to "ARGCluster"
argcluster_tax <- tax_table(Final.ps.DAanalysis.filtered.noblanks)[, "ARGCluster"]
rownames(argcluster_tax) <- argcluster_tax[, "ARGCluster"]

# Create a new phyloseq object
Final.ps.DAanalysis.filtered.noblanks_argclust <- phyloseq(
  otu_table(Final.ps.DAanalysis.filtered.noblanks),
  sample_data(Final.ps.DAanalysis.filtered.noblanks),
  tax_table = argcluster_tax
)

# Run ANCOMBC2 analysis
out = ancombc2(
  data = Final.ps.DAanalysis.filtered.noblanks_argclust, 
  assay_name = NULL,
  p_adj_method = "BH", 
  prv_cut = 0, 
  fix_formula = "copdcaco",
  group = "copdcaco", 
  struc_zero = TRUE, 
  neg_lb = FALSE, 
  alpha = 0.05, 
  global = TRUE,
  n_cl =1, 
  verbose = TRUE
)

saveRDS(out, "Output_files//Differential_abundance//ANCOMBC2_output.rds")

# Differential abundance test 
ANCOMBC2.results <- out$res
ANCOMBC2.results$diff_copdcaco1
ANCOMBC2.results$p_copdcaco1
ANCOMBC2.results$q_copdcaco1
any(ANCOMBC2.results$diff_copdcaco1 == "TRUE")

saveRDS(ANCOMBC2.results, "Output_files//Differential_abundance//ANCOMBC2_results_table.rds")
write.xlsx(ANCOMBC2.results, "Output_files//Differential_abundance//ANCOMBC2_results_table.xlsx")

# Check for structural zeroes
tab_zero = out$zero_ind
tab_zero %>%
    data.table(caption = "The detection of structural zeros")

# N.B copdcaco = 0 (control) is used as the reference group in my case
# lfc_(Intercept) and lfc_copdcaco1: lfc = log fold changes in ARG abundance. lfc_(Intercept): This column represents the LFC for each ARG  between the reference group (Intercept) and itself. In other words, it shows the estimated change in abundance or expression of each taxon within the reference group. The LFC_(Intercept) values indicate how much the abundance or expression of each ARG varies within the reference group. fc_copdcaco1: This column represents the LFC for each ARG or feature between the reference group (Intercept) and the "copdcaco1" group. It shows the estimated change in abundance or expression of each taxon when comparing the reference group to the "copdcaco1" group. A positive LFC indicates an increase in abundance or expression in the "copdcaco1" group compared to the reference group, while a negative LFC suggests a decrease. The magnitude of the LFC_(copdcaco1) values provides information about the size of the difference between these two groups.
# se_(Intercept) and se_copdcaco1: These represent the standard errors associated with the log-fold changes for the reference group and the copdcaco1 group, respectively. The standard error provides a measure of the uncertainty associated with the LFC estimate.
# W_(Intercept) and W_copdcaco1: These values correspond to the Wilcoxon rank-sum test statistics for the reference group and the copdcaco1 group. These statistics are used to assess the significance of differences in microbial abundance between the groups.
# p_(Intercept) and p_copdcaco1: These represent the p-values associated with the Wilcoxon rank-sum tests for the reference group and the copdcaco1 group. A small p-value indicates that there is evidence to reject the null hypothesis, suggesting significant differences in abundance between the groups.
# q_(Intercept) and q_copdcaco1: These values may represent adjusted p-values, often corrected for multiple comparisons. Adjusted p-values take into account the issue of conducting multiple statistical tests and help control the family-wise error rate.
# diff_(Intercept) and diff_copdcaco1: These values typically represent binary indicators (e.g., "TRUE" or "FALSE) that signify whether the corresponding log-fold change is considered significant or not. 

# None come out as significant. 

# Produce horizontal bar plots 
# Create a data frame with the relevant columns from ANCOMBC2.results

data_ANCOMBC2 <- data.frame(
  ARGCluster = rownames(tax_table(Final.ps.DAanalysis.filtered.noblanks_argclust)),
  LogFoldChange = ANCOMBC2.results$lfc_copdcaco1,
  StandardError = ANCOMBC2.results$se_copdcaco1,
  AdjustedPval = ANCOMBC2.results$q_copdcaco1
)

# Determine the fill color based on the sign of LogFoldChange
data_ANCOMBC2$FillColor <- ifelse(data_ANCOMBC2$LogFoldChange > 0, "darkorange", "cornflowerblue")
data_ANCOMBC2$ARGCluster <- reorder(data_ANCOMBC2$ARGCluster, data_ANCOMBC2$LogFoldChange)

# Create the horizontal bar plot - with p values (not adjusted)
ANCOMBC2_barplot <- ggplot(data, aes(y = ARGCluster, x = LogFoldChange, fill = FillColor)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbarh(aes(xmin = LogFoldChange - StandardError, xmax = LogFoldChange + StandardError), height = 0.2) +
  scale_fill_identity() +  # Set fill color to FillColor
  labs(y = "ARG Cluster", x = "Log Fold Change") +
  theme_minimal() + # You can customize the theme as needed
  theme(
    panel.background = element_rect(fill = "white"),  # Set the background to white
    plot.background = element_rect(fill = "white")     # Set the plot area background to white
  ) 


# Show the plot
print(ANCOMBC2_barplot)

ggsave("Output_files//Differential_abundance//horizontal_ANCOMBC2_bar_plot.png", plot = ANCOMBC2_barplot, width = 8, height = 10, units = "in", dpi = 1000)
```

# Wilcoxon rank sum test 
```{r}
# Since all DA analysis methods assume compositionality and perform a log transformation, we are comparing relative abundances of the ARGs between the groups. 
# Instead by using Wilcoxon rank sum test we can compare absolute abundances of the ARGs because they may have different loads. 


# Extract the normalized count data from your phyloseq object
resistome_counts <- otu_table(Final.ps.DAanalysis.filtered.noblanks)

# Extract the sample data to identify COPD cases and controls
sample_data <- sample_data(Final.ps.DAanalysis.filtered.noblanks)

# Create an empty data frame to store the test results
results <- data.frame(Gene = character(0), TestUsed = character(0), p_value = numeric(0))

# Set the significance level for the Shapiro-Wilk test
alpha_shapiro = 0.05

# Loop through each resistance gene
for (gene in colnames(resistome_counts)) {
  # Extract the absolute abundance data for the current gene
  gene_data <- resistome_counts[, gene]
  
  # Combine the data for COPD cases and controls
  combined_data <- c(gene_data[sample_data$copdcaco == '1'], gene_data[sample_data$copdcaco == '0'])
  
  # Perform the Shapiro-Wilk test
  shapiro_test <- shapiro.test(combined_data)
  
  # Check the Shapiro-Wilk test p-value
  if (shapiro_test$p.value < alpha_shapiro) {
    # Use Wilcoxon rank-sum test if Shapiro-Wilk test is significant
    test_result <- wilcox.test(gene_data[sample_data$copdcaco == '1'], gene_data[sample_data$copdcaco == '0'])
    test_used <- "Wilcoxon"} else 
      {
    # Use t-test if Shapiro-Wilk test is not significant
    test_result <- t.test(gene_data[sample_data$copdcaco == '1'], gene_data[sample_data$copdcaco == '0'])
    test_used <- "t-test"}
  
  # Store the test result in the results data frame
  results <- rbind(results, data.frame(Gene = gene, TestUsed = test_used, p_value = test_result$p.value))
}

# Correct for multiple testing using the Benjamini-Hochberg (FDR) method
results$padj <- p.adjust(results$p_value, method = "fdr")
significant_genes <- results$Gene[results$padj < 0.05] # 0 genes are significantly different when corrected for multiple testing.

# View the results (sorted by adjusted p-value)
pvals_gene_COPDvscontrol <- results[order(results$padj), ]
```

