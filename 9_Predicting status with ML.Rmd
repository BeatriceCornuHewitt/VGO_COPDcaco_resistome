## Predicting outcome using Machine learning algorithms
### Support Vector Machine
```{r}
#A support vector machine is a supervised machine learning model that can be used for classification i.e. classifying into COPD or control groups
# The aim is to find a hyperplane that distinctly classifies the data points.
# I give the SVM a set of labelled training data and then see if it’s able to categorise the test dataset. 

# load required package 
dataframe1 <- data.frame(Countdata.DESeq2@otu_table)
dataframe2 <- data.frame(Countdata.DESeq2@sam_data)
dataframe1$copdcaco <- dataframe2$copdcaco
dataframe1 # my df for the analysis 

# setting the features (i.e the 233 genes in the dataset)
dataset <- dataframe1[,1:233]
#encode outcome as factor (COPD/control)
dataframe1$copdcaco <- factor(dataframe1$copdcaco, levels = c(0,1))

# Splitting the dataset into the Training set and Test set
install.packages('caTools')
library(caTools)

set.seed(123)
split <- sample.split(dataframe1$copdcaco, SplitRatio = 0.75)
  
training_set <- subset(dataframe1, split == TRUE)
test_set <- subset(dataframe1, split == FALSE)

# Inspect the splitting of the data 
split 
training_set #52 samples in training set
test_set # 17 in test set 


# Fitting SVM to the Training set
dataset
classifier <- svm(formula = copdcaco ~ .,
                 data = training_set,
                 type = 'C-classification',
                 kernel = 'linear')
classifier

# Predicting the Test set results
y_pred <- predict(classifier, newdata = test_set)
y_pred

# Making the Confusion Matrix
confusion.matrix <- table(test_set[, 234], y_pred)
confusion.matrix
# This is the confusion matrix that came from testing the algorithm on the test dataset: columns show predictions from the model and rows are actual values in the test dataset. This shows the model had 5 false positives and 4 false negatives, out of a total of 17 samples – doesn’t seem great. 

# calculating accuracy of the model prediction from the confusion matrix 
(3+5)/(17)

# Calculate AUC of model 
library(ModelMetrics)
auc.linear  <- auc(test_set$copdcaco, y_pred)
auc.linear

# Try SVM with radial kernel 
dataset
classifier.radial <- svm(formula = copdcaco ~ .,
                 data = training_set,
                 type = 'C-classification',
                 kernel = 'radial')
classifier.radial

# Predicting the Test set results
y_pred_radial <- predict(classifier.radial, newdata = test_set)
y_pred_radial

# Making the Confusion Matrix
confusion.matrix.radial <- table(test_set[, 234], y_pred_radial)
confusion.matrix.radial

library(ModelMetrics)
aucs.radial  <- auc(test_set$hd, y_pred_radial)
aucs.radial
```


```{r}
# # Other attempt
# dat <-  data.frame(x, y = as.factor(y))
# svmfit <- svm(y ~ ., data = dat, kernel = "radial", cost = 5)
# print(svmfit)
# 
# #plot function for SVM that shows the decision boundary
# plot(svmfit, dat)
# 
# # create grid of values 
# make.grid = function(x, n = 69) {
#   grange = apply(x, 2, range)
#   x1 = seq(from = grange[1,1], to = grange[2,1], length = n)
#   x2 = seq(from = grange[1,2], to = grange[2,2], length = n)
#   expand.grid(X1 = x1, X2 = x2)
```

### Random Forest 
```{r}
library(randomForest)
require(caTools)

head(dataframe1)
summary(dataframe1)
sapply(dataframe1,class)

# Set portion of data aside for testing/training
sample_RF <- sample.split(dataframe1$copdcaco, SplitRatio = .75)
train_RF <- subset(dataframe1, sample_RF == TRUE)
test_RF <- subset(dataframe1, sample_RF == FALSE)
train_RF
test_RF


RF <- randomForest(
  copdcaco ~ .,
  data=train_RF
)

# By default, the number of decision trees in the forest is 500 and the number of features used as potential candidates for each split is 3. The model will automatically attempt to classify each of the samples in the Out-Of-Bag dataset and display a confusion matrix with the results.


# Now, we use our model to predict whether the RF can categorise people into COPD cases and controls 
pred_RF <- predict(RF, newdata=test_RF[-234])

#Since this is a classification problem, we use a confusion matrix to evaluate the performance of our model. Recall that values on the diagonal correspond to true positives and true negatives (correct predictions) whereas the others correspond to false positives and false negatives.
confusionmatrix_RF <- table(test_RF[,234], pred_RF)
confusionmatrix_RF

# accuracy of model
(6+3)/(17)
```