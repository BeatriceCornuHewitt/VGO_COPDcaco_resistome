---
title: "7 - Differential abundance analysis"
author: "b.cornuhewitt@uu.nl"
---
# Packages
```{r}
library(base); library(stats); library(graphics); library(dplyr); library(xlsx); library(ggplot2); library(phyloseq); library(DESeq2); library(ALDEx2)
```

# COPD vs control 

## Preparing data - unfiltered 
```{r}
# Since the DA analyses require count data which has not been corrected for gene length, I need to create a new ps object with only corrections for volume input and qPCR bacterial count
PS_rarefied <- readRDS("../Output_files/Phyloseq_objects/2_COPD_resistome_phyloseq_object_rarefied.RDS") 
# convert otu fpk values directly by matrix manipulation in the ps object using qPCRcounts data frame 
PS_rarefied_16Scorrected <- PS_rarefied
PS_rarefied_16Scorrected@otu_table@.Data <- PS_rarefied_16Scorrected@otu_table@.Data / qPCRcounts[1:73, ]

# check PS 
PS_rarefied_16Scorrected
head(taxa_names(PS_rarefied_16Scorrected))

## Remove duplicate sample (13674) from the dataset
Final_ps_DAanalysis_unclustered <- prune_samples(sample_names(PS_rarefied_16Scorrected) != "13674", PS_rarefied_16Scorrected) 
# Final PS object therefore now has 72 samples in total (35 cases, 34 controls, 3 blanks)

# This is the ps object to be used for DA analysis (not gene length corrected but corrected for input volumes and qPCR bacterial counts). 
# Now need to cluster at the 90% identity level 

# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
Final_ps_DAanalysis <- tax_glom2(Final_ps_DAanalysis_unclustered, taxrank=rank_names(Final_ps_DAanalysis_unclustered)[6], NArm=TRUE)
taxa_names(Final_ps_DAanalysis)
# Taxa names are not correct
tax_table(Final_ps_DAanalysis)
taxa_names(Final_ps_DAanalysis)
otu_table(Final_ps_DAanalysis)

# Save normalised & 16S qPCR-corrected PS object ready for DA analysis input
saveRDS(Final_ps_DAanalysis, "../Output_files/Phyloseq_objects/7_COPD_resistome_phyloseq_object_rarefied_16SqPCRcorrected.RDS")

# Rename ARGs to their cluster name
Final_ps_DAanalysis_clusternames <- Final_ps_DAanalysis
colnames(Final_ps_DAanalysis_clusternames@otu_table) <- c("aac(3)-II_clust","aac(3)-Iva","aac(6')-aph(2'')_clust","aadA_ant(3'')-Ia_clust","aadA_clust1","aadD","ant(6)-Ia_clust2","aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(3')-Ib","aph(3')-III","aph(4)-Ia","aph(6)-Id","str","blaACT_clust","blaACT_CMG_MIR_clust","blaBRO","blaCARB_clust2","blaCTX-M_clust1","blaOXA-22","blaOXA-395_clust","blaOXA-60_clust","blaOXA-85","blaOXA_clust19","blaOXA_clust3","blaOXA_clust8","blaOXA_clust9","blaOXY_clust1","blaSPU-1","blaTEM_clust","blaZ_clust","cfxA_clust","mecA_clust","mecA1","penA","fusB","lsa(A)","lsa(C)","erm(A)_2_AF002716","erm(B)_clust","erm(C)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","lnu(C)","mdf(A)","mef(A)-3","mef(A)_clust","mph(A)","mph(C)","msr(A)","msr(D)","msr(E)","vga(A)_clust","cat(pC194)","cat_2","catA1","catQ","catS","cml_clust","cmx","cfr(C)","sul1","sul2","tet(32)","tet(33)","tet(37)","tet(39)","tet(40)","tet(44)","tet(A)","tet(B)","tet(C)","tet(G)","tet(K)","tet(L)_clust1","tet(M)","tet(O)","tet(O/32/O)","tet(O/W/32/O/W/O)","tet(O/W/O)-1","tet(Q)","tet(T)","tet(W)","dfrA15_clust")

saveRDS(Final_ps_DAanalysis_clusternames, "../Output_files/Phyloseq_objects/8_COPD_resistome_phyloseq_object_rarefied_16SqPCRcorrected_clusternames.RDS")

# Remove blanks from PS object 
blanks <- subset_samples(Final_ps_DAanalysis_clusternames@sam_data, copdcaco == "blanc")
# Convert 'blanks' to a character vector of sample names
blank_names <- as.character(sample_names(blanks))
# Prune samples from 'ARGcluster.aggl'
Final_ps_DAanalysis_clusternames_noblanks <- Final_ps_DAanalysis_clusternames
Final_ps_DAanalysis_clusternames_noblanks <- prune_samples(!sample_names(Final_ps_DAanalysis_clusternames_noblanks)%in%blank_names, Final_ps_DAanalysis_clusternames_noblanks)
Final_ps_DAanalysis_clusternames_noblanks
```
## Preparing data - filtered 
```{r}
# Copy over ps object to be used
Final_ps_DAanalysis_filtered <- Final_ps_DAanalysis

# Remove blanks from PS object 
blanks <- subset_samples(Final_ps_DAanalysis_filtered@sam_data, copdcaco == "blanc")
# Convert 'blanks' to a character vector of sample names
blank_names <- as.character(sample_names(blanks))
# Prune samples from 'ARGcluster.aggl'
Final_ps_DAanalysis_filtered <- Final_ps_DAanalysis_filtered
Final_ps_DAanalysis_filtered <- prune_samples(!sample_names(Final_ps_DAanalysis_filtered)%in%blank_names, Final_ps_DAanalysis_filtered)

# Create prevalence-abundance filter
# 0.1% abundant, 15% prevalent:  
pres_abund_filter_DAanalysis <- function(Final_ps_DAanalysis_filtered, pres=10.35, abund=0.001) { # Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
filter_taxa(Final_ps_DAanalysis_filtered, function(x) sum(x >= abund)>=pres, TRUE) }
# apply filter
Final_ps_DAanalysis_filtered <- transform_sample_counts(Final_ps_DAanalysis_filtered, function(x) x/sum(x) *100 ) %>% pres_abund_filter_DAanalysis()
# Now there are 30 taxa (instead of 85)

# Now rename to actual cluster names
taxa_names(Final_ps_DAanalysis_filtered)

colnames(Final_ps_DAanalysis_filtered@otu_table) <- c("aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(4)-Ia","aph(6)-Id","blaOXA-60_clust","blaSPU-1","blaTEM_clust","cfxA_clust","penA","lsa(C)","erm(B)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","mef(A)-3","mef(A)_clust","msr(D)","cat(pC194)","sul1","sul2","tet(32)","tet(37)","tet(A)","tet(B)","tet(C)","tet(M)","tet(O)","tet(O/W/32/O/W/O)","tet(Q)","tet(W)")
```
## Heatmap to check distribution of ARG clusters post filtering
```{r}
# Create a heatmap now on the cluster 90 level as this is a better representation of the data 
# Extract abundance matrix from cluster 90 agglomerated ps object
ARGclustertable_filtered <- as(otu_table(Final_ps_DAanalysis_filtered), "matrix")
# transform into a data frame
ARGcluster_filtered_dataframe <- as.data.frame(ARGclustertable_filtered)
ARGcluster_filtered_dataframe
# Examine actual cluster 90 names and names assigned in the ps object
Final_ps_DAanalysis_filtered@tax_table[,6]

# column names are (specific) ARG names, agglomeration is correct (lowest level is ARG cluster) but col names are not correct - I will rename the column names to the AMR classes for presentation in the heatmap
colnames(ARGcluster_filtered_dataframe) <- c("aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(4)-Ia","aph(6)-Id","blaOXA-60_clust","blaSPU-1","blaTEM_clust","cfxA_clust","penA","lsa(C)","erm(B)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","mef(A)-3","mef(A)_clust","msr(D)","cat(pC194)","sul1","sul2","tet(32)","tet(37)","tet(A)","tet(B)","tet(C)","tet(M)","tet(O)","tet(O/W/32/O/W/O)","tet(Q)","tet(W)")

# Check the renaming has been performed correctly
colnames(ARGcluster_filtered_dataframe)

# transform the raw counts of reads to proportions of total ARG clusters in each sample 
ARGcluster_filtered_dataframe.prop <- ARGcluster_filtered_dataframe/rowSums(ARGcluster_filtered_dataframe)
# Examine the dataframe 
ARGcluster_filtered_dataframe.prop

# calculate the Bray-Curtis dissimilarity matrix on the full dataset
ARGCluster.filtered.BCdist <- vegdist(ARGcluster_filtered_dataframe.prop, method = "bray")

# perform hierarchical cluster analysis using the BC dissimilarities 
# each sample is assigned to its own cluster and then the algorithm proceeds iteratively, at each stage joining the two most similar clusters, continuing until there is just a single cluster.
ARGCluster.hierarchicalclust <- hclust(ARGCluster.filtered.BCdist, "aver")

# Create a heatmap at the ARG cluster level
COPDcontrolblank <- Final_ps_DAanalysis_filtered@sam_data$copdcaco 
COPDcontrolblank<- replace(COPDcontrolblank, which(COPDcontrolblank == "0"), "blue")
COPDcontrolblank<-replace(COPDcontrolblank, which(COPDcontrolblank == "1"), "red")
COPDcontrolblank # check that colours are allocated to the groups

heatmap_ARGClusterlevel <- heatmap(
  as.matrix(ARGcluster_filtered_dataframe.prop),
  Rowv = as.dendrogram(ARGCluster.hierarchicalclust),
  RowSideColors = COPDcontrolblank,
  margins = c(11, 5),
  xlab = "ARGCluster",
  ylab = "SampleIDs",
  main = "Hierarchical clustering heatmap at 90% ARG cluster level",
  las = 2,  # Set label orientation to horizontal
  cexRow = 0.8,
  cexCol = 0.5# Adjust the font size of the row labels
)
# Note that the samples are not in the same order as that in the matrix - heatmap() reorders both variables and observations using the BC clustering algorithm: it computes the distance between each pair of rows and columns and try to order them by similarity.

```
## DESeq2 
```{r}
# Now run DESeq analysis again with this newly filtered data on COPD status 
Final_ps_DAanalysis_filtered@sam_data$copdcaco
# Convert copdcaco column to factor variable (from character)
Final_ps_DAanalysis_filtered@sam_data$copdcaco <- as.factor(Final_ps_DAanalysis_filtered@sam_data$copdcaco)
deseq2_copd_filt <- phyloseq_to_deseq2(Final_ps_DAanalysis_filtered, ~copdcaco)
head(deseq2_copd_filt)
# N.B when we use phyloseq_to_deseq2, it converts all counts into integers, therefore for some ARGs which only have counts < 0.1, these all become zero, and therefore BaseMean = 0 and log2 fold changes are NA
# RUN  DESeq function 
deseq2_copd_filt <- DESeq(deseq2_copd_filt, parallel = FALSE)
deseq2_copd_results_filt <- results(deseq2_copd_filt)
deseq2_copd_results_filt
deseq2_copd_results_filt_df <- as.data.frame(deseq2_copd_results_filt)
write.xlsx(deseq2_copd_results_filt_df, "../Output_files/Differential_abundance/DESeq_results_table.xlsx", row.names = TRUE)

#summary of differential gene expression
summary(deseq2_copd_results_filt)
head(deseq2_copd_results_filt)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2_copd_results_filt)$description
# Order the results table by the smallest p value:
deseq2_copd_results_filt.ordered <- deseq2_copd_results_filt[order(deseq2_copd_results_filt$pvalue),]
deseq2_copd_results_filt.ordered 
sum(deseq2_copd_results_filt.ordered$padj < 0.05, na.rm=TRUE) # I now find 1 ARG cluster which has a p-value of <0.1

# Produce horizontal bar plots 
data_DESEq2 <- data.frame(
  ARGCluster = rownames(deseq2_copd_results_filt),
  LogFoldChange = deseq2_copd_results_filt$log2FoldChange,
  StandardError = deseq2_copd_results_filt$lfcSE,
  AdjustedPval = deseq2_copd_results_filt$padj
)

# Filter out rows with NA LogFoldChange - some of these are NA because DESeq can only deal with integers, so any ARGs that have abundances < 1 have an overall BaseMean of 0 and therefore do not have a corresponding log2 fold change
data_DESEq2 <- data_DESEq2[complete.cases(data_DESEq2), ]

# Determine the fill color based on the sign of LogFoldChange
data_DESEq2$FillColor <- ifelse(data_DESEq2$LogFoldChange > 0, "darkorange", "cornflowerblue")
data_DESEq2$ARGCluster <- reorder(data_DESEq2$ARGCluster, data_DESEq2$LogFoldChange)
# Create the horizontal bar plot - with p values (not adjusted)
DESeq2_barplot <- ggplot(data_DESEq2, aes(y = ARGCluster, x = LogFoldChange, fill = FillColor)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbarh(aes(xmin = LogFoldChange - StandardError, xmax = LogFoldChange + StandardError), height = 0.2) +
  scale_fill_identity() +  # Set fill color to FillColor
  labs(y = "ARG Cluster", x = "Log2 Fold Change") +
  theme_minimal() + # You can customize the theme as needed
  theme(
    panel.background = element_rect(fill = "white"),  # Set the background to white
    plot.background = element_rect(fill = "white")     # Set the plot area background to white
  )

# Show the plot
print(DESeq2_barplot)
ggsave("../Output_files/Differential_abundance/horizontal_DESeq2_bar_plot.png", plot = DESeq2_barplot, width = 8, height = 10, units = "in", dpi = 1000)


# create plot 
# Plot to show the log2 fold changes attributable to a given variable over the mean of normalized counts for all the samples in the DESeqDataSet. Points will be colored red if the adjusted p value is less than 0.1. Points which fall out of the window are plotted as open triangles pointing either up or down.
plotMA(deseq2_copd_results_filt.ordered, ylim=c(-2,2))
# Shrink the log2fold changes as these provide better LFC estimates
resultsNames(deseq2.exp.DISP_EUinPM10_AnnualAv_WP99.5.cont)
resultsNames(deseq2_copd_filt)
deseq2_copd_filt.lfcshrink <- lfcShrink(deseq2_copd_filt, coef="copdcaco_1_vs_0", type="apeglm")
deseq2_copd_filt.lfcshrink
#It is more useful visualize the MA-plot for the shrunken log2 fold changes, which remove the noise associated with log2 fold changes from low count genes without requiring arbitrary filtering thresholds.
plotMA(deseq2_copd_results_filt, ylim=c(-2,2)) # plot looks odd...?

# Using ggplot2 to create an MA plot
# Coerce to a data frame
deseq2_copd_results_filt.copdcaco.MAplot <- as.data.frame(deseq2_copd_results_filt)
# Examine this data frame
head(deseq2_copd_results_filt.copdcaco.MAplot)
# Set a boolean column for significance
deseq2_copd_results_filt.copdcaco.MAplot$significant <- ifelse(deseq2_copd_results_filt.copdcaco.MAplot$padj < .05, "Significant", NA)
# Plot the results in an MA plot 
ggplot(deseq2_copd_results_filt.copdcaco.MAplot, aes(baseMean, log2FoldChange, colour=significant)) + geom_point(size=3) + scale_y_continuous(limits=c(-2, 2)) + scale_x_log10() + geom_hline(yintercept = 0, colour="red", size=0.5) + labs(x="Mean of ARG counts", y="Log2 fold change - COPD case to control") +  scale_colour_manual(name="q-value", values=("Significant"="red"), na.value="black") + theme_bw()

# Create a plot of counts 
deseq2_copd_results_filt.ordered[1,]
rowname(deseq2_copd_results_filt.ordered[1,]) <- ""

plotCounts(deseq2_copd_filt, gene=which.min(deseq2_copd_results_filt$padj), intgroup="copdcaco", xlab = "Control (0) vs COPD case (1)")
```
## ALDEx2 
```{r}
# copy over the previously agglomerated and filtered ps object from my above DESeq2 analysis
Final_ps_DAanalysis_filtered
tax_table(Final_ps_DAanalysis_filtered)
# 30 ARG Clusters 

# create otu table for aldex2 analysis - this needs to be "A non-negative, integer-only data.frame or matrix with unique names for all rows and columns. Rows should contain genes and columns should contain sequencing read counts (i.e., sample vectors). Rows with 0 reads in each sample are deleted prior to analysis
Final_ps_DAanalysis_filtered.otutab.trans <- t(otu_table(Final_ps_DAanalysis_filtered))

Final_ps_DAanalysis_filtered.otutab.trans.bill.round <- round(Final_ps_DAanalysis_filtered.otutab.trans * 1000000000,0) # I multiply by billion as aldex2 requires that reads are all integers 
otutab.for.ALDEx2.filtered <- data.frame(Final_ps_DAanalysis_filtered.otutab.trans.bill.round)
colnames(otutab.for.ALDEx2.filtered) <- colnames(Final_ps_DAanalysis_filtered.otutab.trans.bill.round)

# Then we set the comparison groups. This must be a vector of conditions in the same order as the samples in the input counts table.
sampledata.for.ALDEx2 <- sample_data(Final_ps_DAanalysis_filtered)$copdcaco
sampledata_numeric <- as.numeric(as.character(sampledata.for.ALDEx2))
# Run the aldex command - I ask aldex to do a 2-sample t-test to calculate effect sizes,
# The aldex function is a wrapper that performs log-ratio transformation and statistical testing in a single line of code. Specifically, this function: (a) generates Monte Carlo samples of the Dirichlet distribution for each sample, (b) converts each instance using a log-ratio transform, then (c) returns test results for two sample (Welch’s t, Wilcoxon) or multi-sample (glm, Kruskal-Wallace) tests. This function also estimates effect size for two sample analyses.
ALDEx2.filtered.COPDcontrol <- ALDEx2::aldex(reads=otutab.for.ALDEx2.filtered, conditions= sampledata_numeric, test="t", effect = TRUE, denom="iqlr") # Aldex parameters set: test = "t" runs Welch's t-test and Wilcoxon tests. Effect = TRUE - tells aldex to calculate effect sizes. Denom="iqlr" is commonly used and indicates which features to retain as the denominator for the geometric mean calculation - "iqlr" accounts for data with systematic variation. 

ALDEx2.filtered.COPDcontrol
write.xlsx(ALDEx2.filtered.COPDcontrol, "../Output_files/Differential_abundance/ALDEx2.COPDcontrol.results.table.xlsx", row.names = TRUE)


# Create MA and Effect plots of ALDEx2 output
# create Bland-Altman plot 
par(mfrow = c(1, 3))
aldex.plot(ALDEx2.filtered.COPDcontrol, type="MA", test="welch", xlab="Log-ratio abundance",
    ylab="Difference")

aldex.plot(ALDEx2.filtered.COPDcontrol, type="MW", test="welch", xlab="Dispersion",
    ylab="Difference", all.cex = 3)

aldex.plot(ALDEx2.filtered.COPDcontrol, type="volcano", test="welch", xlab="Difference",
    ylab="-1(log10(q))", main='Volcano plot')


# Compute an aldex.clr object
ALDEx2.filtered.COPDcontrol.clr <- aldex.clr(otutab.for.ALDEx2.filtered, sampledata.for.ALDEx2, mc.samples=128, denom="all", verbose=F)
# aldex.ttest calculates the expected values of the Wilcoxon Rank Sum test and Welch’s t-test on the data returned by aldex.clr.
ALDEx2.filtered.COPDcontrol.ttest <- aldex.ttest(ALDEx2.filtered.COPDcontrol.clr, paired.test=FALSE, verbose=FALSE)
ALDEx2.filtered.COPDcontrol.ttest 
# where: we.ep - Expected P value of Welch’s t test, we.eBH - Expected Benjamini-Hochberg corrected P value of Welch’s t test, wi.ep - Expected P value of Wilcoxon rank test, wi.eBH - Expected Benjamini-Hochberg corrected P value of Wilcoxon test
# I will look at Wilcoxon test results with BH correction (we.eBH)
# Reorder the p-values based on size of wi.eBH value
reOrdered_ALDEx2.filtered.COPDcontrol.ttest <- ALDEx2.filtered.COPDcontrol.ttest[order(ALDEx2.filtered.COPDcontrol.ttest$wi.eBH),]
reOrdered_ALDEx2.filtered.COPDcontrol.ttest
# check to identify how many values are significant from the t-test (q<0.1)
which(ALDEx2.filtered.COPDcontrol.ttest$wi.eBH < 0.1)
# 0 ARG clusters are differentially abundant 
# Therefore we conclude that using the ALDEx2 method, we do not identify any ARGs which are differentially abundant

# Estimate effect size and the within and between condition values in the case of two conditions
ALDEx2.filtered.COPDcontrol.effect <- aldex.effect(ALDEx2.filtered.COPDcontrol.clr, CI=T, verbose=FALSE)
```
# Livestock exposures
## Preparing data - unfiltered 
```{r}
# Since the DA analyses require count data which has not been corrected for gene length, I need to create a new ps object with only corrections for volume input and qPCR bacterial count
PS_rarefied <- readRDS("../Output_files/Phyloseq_objects/2_COPD_resistome_phyloseq_object_rarefied.RDS") 
# convert otu fpk values directly by matrix manipulation in the ps object using qPCRcounts data frame 
PS_rarefied_16Scorrected <- PS_rarefied
PS_rarefied_16Scorrected@otu_table@.Data <- PS_rarefied_16Scorrected@otu_table@.Data / qPCRcounts[1:73, ]
# check PS 
PS_rarefied_16Scorrected
head(taxa_names(PS_rarefied_16Scorrected))

## Remove duplicate sample (13674) from the dataset
Final_ps_DAanalysis_unclustered <- prune_samples(sample_names(PS_rarefied_16Scorrected) != "13674", PS_rarefied_16Scorrected) 
# Final PS object therefore now has 72 samples in total (35 cases, 34 controls, 3 blanks)

# Now add livestock exposure metadata - sam.data.new created as above
Final_ps_DAanalysis_unclustered.exp <- Final_ps_DAanalysis_unclustered
sample_data(Final_ps_DAanalysis_unclustered.exp) <- sam.data.new

# This is the ps object to be used for DA analysis (not gene length corrected but corrected for input volumes and qPCR bacterial counts). 
# Now need to cluster at the 90% identity level 

# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
Final_ps_DAanalysis.exp <- tax_glom2(Final_ps_DAanalysis_unclustered.exp, taxrank=rank_names(Final_ps_DAanalysis_unclustered.exp)[6], NArm=TRUE)

# ARG cluster names are not correct
tax_table(Final_ps_DAanalysis.exp)
taxa_names(Final_ps_DAanalysis.exp)
otu_table(Final_ps_DAanalysis.exp)

# Rename ARG clusters to their cluster name
Final_ps_DAanalysis.exp.clusternames <- Final_ps_DAanalysis.exp
colnames(Final_ps_DAanalysis.exp.clusternames@otu_table) <- c("aac(3)-II_clust","aac(3)-Iva","aac(6')-aph(2'')_clust","aadA_ant(3'')-Ia_clust","aadA_clust1","aadD","ant(6)-Ia_clust2","aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(3')-Ib","aph(3')-III","aph(4)-Ia","aph(6)-Id","str","blaACT_clust","blaACT_CMG_MIR_clust","blaBRO","blaCARB_clust2","blaCTX-M_clust1","blaOXA-22","blaOXA-395_clust","blaOXA-60_clust","blaOXA-85","blaOXA_clust19","blaOXA_clust3","blaOXA_clust8","blaOXA_clust9","blaOXY_clust1","blaSPU-1","blaTEM_clust","blaZ_clust","cfxA_clust","mecA_clust","mecA1","penA","fusB","lsa(A)","lsa(C)","erm(A)_2_AF002716","erm(B)_clust","erm(C)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","lnu(C)","mdf(A)","mef(A)-3","mef(A)_clust","mph(A)","mph(C)","msr(A)","msr(D)","msr(E)","vga(A)_clust","cat(pC194)","cat_2","catA1","catQ","catS","cml_clust","cmx","cfr(C)","sul1","sul2","tet(32)","tet(33)","tet(37)","tet(39)","tet(40)","tet(44)","tet(A)","tet(B)","tet(C)","tet(G)","tet(K)","tet(L)_clust1","tet(M)","tet(O)","tet(O/32/O)","tet(O/W/32/O/W/O)","tet(O/W/O)-1","tet(Q)","tet(T)","tet(W)","dfrA15_clust")

```
## Preparing data - filtered 
```{r}
# Copy over ps object to be used
Final_ps_DAanalysis.exp.filtered <- Final_ps_DAanalysis.exp

# Create prevalence-abundance filter
# 0.1% abundant, 15% prevalent:  
pres_abund_filter_DAanalysis <- function(Final_ps_DAanalysis.exp.filtered, pres=10.35, abund=0.001) { # Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
filter_taxa(Final_ps_DAanalysis.exp.filtered, function(x) sum(x >= abund)>=pres, TRUE) }
# apply filter
Final_ps_DAanalysis.exp.filtered <- transform_sample_counts(Final_ps_DAanalysis.exp.filtered, function(x) x/sum(x) *100 ) %>% pres_abund_filter_DAanalysis()
# Now there are 30 taxa (instead of 85)

# Now rename to actual cluster names
taxa_names(Final_ps_DAanalysis.exp.filtered)
Final_ps_DAanalysis.exp.filtered.clusternames <- Final_ps_DAanalysis.exp.filtered
colnames(Final_ps_DAanalysis.exp.filtered.clusternames@otu_table) <- c("aph(3'')-Ib","aph(3')-Ia_aph(3')-Ic","aph(4)-Ia","aph(6)-Id","blaOXA-60_clust","blaSPU-1","blaTEM_clust","cfxA_clust","penA","lsa(C)","erm(B)_clust","erm(F)_clust","erm(T)_4_AJ488494","erm(X)_clust","mef(A)-3","mef(A)_clust","msr(D)","cat(pC194)","sul1","sul2","tet(32)","tet(37)","tet(A)","tet(B)","tet(C)","tet(M)","tet(O)","tet(O/W/32/O/W/O)","tet(Q)","tet(W)")
```
## DESeq2
```{r}
# copy over the previously agglomerated and filtered ps object from my above DESeq2 analysis
ARGcluster.aggl.DESeq2.filtered.exp <- ARGcluster.aggl.DESeq2.filtered.relative
ARGcluster.aggl.DESeq2.filtered.exp
tax_table(ARGcluster.aggl.DESeq2.filtered.exp)
# 30 ARG Clusters 
ARGcluster.aggl.DESeq2.filtered.exp@sam_data # But the sample data in this ps object does not include the exposure proxy data so I need to add this in
sam.data.new <- as.data.frame(sample_data(livestock.exp.df.noblanks.df))
sample_data(ARGcluster.aggl.DESeq2.filtered.exp) <- sam.data.new
ARGcluster.aggl.DESeq2.filtered.exp@sam_data

# I will start with continuous exposure covariates in the DESeq2 analysis as a constant fold change is possible for each unit of increase of the variables 
# Now ready to run the deseq2 analysis using the phyloseq_to_deseq2 function
# Start with assessing endotoxin concentration effects
# Convert phyloseq data to DESeq2 dataset object
deseq2.exp.filtered.endotoxin <- phyloseq_to_deseq2(ARGcluster.aggl.DESeq2.filtered.exp,~DISP_EUinPM10_AnnualAv_WP99.5)

# RUN  DESeq function 
deseq2.exp.filtered.endotoxin <- DESeq(deseq2.exp.filtered.endotoxin)
deseq2.results.exp.filtered.endotoxin<- results(deseq2.exp.filtered.endotoxin)
deseq2.results.exp.filtered.endotoxin
#summary of differential gene expression
summary(deseq2.results.exp.filtered.endotoxin)
head(deseq2.results.exp.filtered.endotoxin)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2.results.exp.filtered.endotoxin)$description
# Order the results table by the smallest p value:
deseq2.results.exp.filtered.endotoxin.ordered <- deseq2.results.exp.filtered.endotoxin[order(deseq2.results.exp.filtered.endotoxin$pvalue),]
deseq2.results.exp.filtered.endotoxin.ordered 
# How many adjusted p-values are < 0.1? 
sum(deseq2.results.exp.filtered.endotoxin.ordered$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Now look at PM10 concentration effects on differential abundance
# Convert phyloseq data to DESeq2 dataset object
deseq2.exp.filtered.PM10 <- phyloseq_to_deseq2(ARGcluster.aggl.DESeq2.filtered.exp,~DISP_PM10CONC_AnnualAv_WP99.5)
# RUN  DESeq function 
deseq2.exp.filtered.PM10 <- DESeq(deseq2.exp.filtered.PM10)
deseq2.results.exp.filtered.PM10 <- results(deseq2.exp.filtered.PM10)
deseq2.results.exp.filtered.PM10
#summary of differential gene expression
summary(deseq2.results.exp.filtered.PM10)
head(deseq2.results.exp.filtered.PM10)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2.results.exp.filtered.PM10)$description
# Order the results table by the smallest p value:
deseq2.results.exp.filtered.PM10.ordered <- deseq2.results.exp.filtered.PM10[order(deseq2.results.exp.filtered.PM10$pvalue),]
deseq2.results.exp.filtered.PM10.ordered #erm(T)_4_AJ488494 has the greatest difference for each fold change in endotoxin concentration
# How many adjusted p-values are < 0.1? 
sum(deseq2.results.exp.filtered.PM10.ordered$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1


# Now look at nhorsesWghtDist.3000m.sum effects on differential abundance
# Convert phyloseq data to DESeq2 dataset object
deseq2.exp.filtered.nhorsesWghtDist.3000m.sum.cont <- phyloseq_to_deseq2(ARGcluster.aggl.DESeq2.filtered.exp,~nhorsesWghtDist.3000m.sum)
# RUN  DESeq function 
deseq2.exp.filtered.nhorsesWghtDist.3000m.sum.cont <- DESeq(deseq2.exp.filtered.nhorsesWghtDist.3000m.sum.cont)
deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont <- results(deseq2.exp.filtered.nhorsesWghtDist.3000m.sum.cont)
deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont
#summary of differential gene expression
summary(deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont)
head(deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont)$description
# Order the results table by the smallest p value:
deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont.ordered <- deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont[order(deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont$pvalue),]
deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont.ordered
# How many adjusted p-values are < 0.1? 
sum(deseq2.results.exp.filtered.nhorsesWghtDist.3000m.sum.cont$padj < 0.1, na.rm=TRUE) # 3 ARG clusters have p-value <0.1

# Now look at ngoatsWghtDist.3000m.sum effects on differential abundance
# Convert phyloseq data to DESeq2 dataset object
deseq2.exp.filtered.ngoatsWghtDist.3000m.sum.cont <- phyloseq_to_deseq2(ARGcluster.aggl.DESeq2.filtered.exp,~ngoatsWghtDist.3000m.sum)
# RUN  DESeq function 
deseq2.exp.filtered.ngoatsWghtDist.3000m.sum.cont <- DESeq(deseq2.exp.filtered.ngoatsWghtDist.3000m.sum.cont)
deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont <- results(deseq2.exp.filtered.ngoatsWghtDist.3000m.sum.cont)
deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont
#summary of differential gene expression
summary(deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont)
head(deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont)
# Information about which variables and tests were used for the results is given by this function
mcols(deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont)$description
# Order the results table by the smallest p value:
deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont.ordered <- deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont[order(deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont$pvalue),]
deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont.ordered 
# How many adjusted p-values are < 0.1? 
sum(deseq2.results.exp.filtered.ngoatsWghtDist.3000m.sum.cont$padj < 0.1, na.rm=TRUE) # 3 ARG clusters have p-value <0.1
```
## ALDEx2
```{r}
# copy over the previously agglomerated and filtered ps object from my above DESeq2 analysis
ARGcluster.aggl.ALDEx2.filtered.exp <- ARGcluster.aggl.DESeq2.filtered.relative
ARGcluster.aggl.ALDEx2.filtered.exp
tax_table(ARGcluster.aggl.ALDEx2.filtered.exp)
# 30 ARG Clusters 
ARGcluster.aggl.ALDEx2.filtered.exp@sam_data # But the sample data in this ps object does not include the exposure proxy data so I need to add this in
sam.data.new <- as.data.frame(sample_data(livestock.exp.df.noblanks.df))
sample_data(ARGcluster.aggl.ALDEx2.filtered.exp) <- sam.data.new
ARGcluster.aggl.ALDEx2.filtered.exp@sam_data

# create otu table for aldex2 analysis - this needs to be "A non-negative, integer-only data.frame or matrix with unique names for all rows and columns. Rows should contain genes and columns should contain sequencing read counts (i.e., sample vectors). Rows with 0 reads in each sample are deleted prior to analysis
ALDEx2.filtered.exp.otutable.trans <- t(otu_table(ARGcluster.aggl.ALDEx2.filtered.exp))
ALDEx2.filtered.exp.otutable.trans.bill.round <- round(ALDEx2.filtered.exp.otutable.trans * 1000000000,0) # I multiply by billion as aldex2 requires that reads are all integers 
otutab.for.ALDEx2.exp.filtered <- data.frame(ALDEx2.filtered.exp.otutable.trans.bill.round)

# Firstly create the aldex.clr object
ALDEx2.exp.filtered.clr <- aldex.clr(otutab.for.ALDEx2.exp.filtered, mc.samples = 128, verbose = FALSE, useMC=FALSE)
# Then we set the comparison groups. This must be a vector of conditions in the same order as the samples in the input counts table.
ALDEx2.exp.filtered.DISPendotoxin <- sample_data(ARGcluster.aggl.ALDEx2.filtered.exp)$DISP_EUinPM10_AnnualAv_WP99.5
# Instead of using the simple aldex() function, I need to use aldex.corr as I am using a continuous variable (e.g. endotoxin concentration to begin with)
# Now run the correlation assessment 
# aldex.corr calculates the expected values for the correlation between each feature and a continuous variable, using data returned returned by aldex.clr and a vector of the continuous variable.It returns results of Pearson, Spearman and Kendall tests.
aldex2.filtered.endotoxin<- aldex.corr(ALDEx2.exp.filtered.clr,ALDEx2.exp.filtered.DISPendotoxin)
aldex2.filtered.endotoxin
# aldex.corr calculates the expected values for the correlation between each feature and a continuous variable (dispersion modelled endotoxin in this case), using data returned returned by aldex.clr and a vector of the continuous variable. Returns results of Pearson, Spearman and Kendall tests.
# I will look at the BH corrected pearson correlation coefficient p-value (this is the column named: "pearson.eBH" (expected Benjamini-Hochberg corrected P value of the Pearson Product moment value for each feature)
aldex2.filtered.endotoxin_reordered <- aldex2.filtered.endotoxin[order(aldex2.filtered.endotoxin$pearson.eBH),]
# check the ARGs that were previously identified as differentially abundant to see whether there are significant correlations identified by ALDEx2
count(aldex2.filtered.endotoxin$pearson.eBH < 0.1) 
# 1 ARG cluster has an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1: blaSPU-1

# Test for correlation with dispersion modelled PM10 now
ALDEx2.exp.DISPPM10 <- sample_data(ARGcluster.aggl.ALDEx2.filtered.exp)$DISP_PM10CONC_AnnualAv_WP99.5
aldex2.filtered.PM10<- aldex.corr(ALDEx2.exp.filtered.clr,ALDEx2.exp.DISPPM10)
aldex2.filtered.PM10
count(aldex2.filtered.PM10$pearson.eBH < 0.1) # No ARG clusters are correlated significantly to dispersion modelled PM10

# Test for correlation with Number of horses weighted to distance in a 3000m buffer
ALDEx2.exp.nhorsesWghtDist.3000m.sum <- ARGcluster.aggl.ALDEx2.filtered.exp@sam_data$nhorsesWghtDist.3000m.sum
aldex2.filtered.nhorsesWghtDist.3000m.sum<- aldex.corr(ALDEx2.exp.filtered.clr,ALDEx2.exp.nhorsesWghtDist.3000m.sum)
aldex2.filtered.nhorsesWghtDist.3000m.sum
count(aldex2.filtered.nhorsesWghtDist.3000m.sum$pearson.eBH < 0.1) # No ARG clusters are correlated significantly to nhorsesWghtDist.3000m.sum

# Test for correlation with Number of goats weighted to distance in a 3000m buffer
ALDEx2.exp.ngoatsWghtDist.3000m.sum <- ARGcluster.aggl.ALDEx2.filtered.exp@sam_data$ngoatsWghtDist.3000m.sum
aldex2.filtered.ngoatsWghtDist.3000m.sum<- aldex.corr(ALDEx2.exp.filtered.clr,ALDEx2.exp.ngoatsWghtDist.3000m.sum)
aldex2.filtered.ngoatsWghtDist.3000m.sum
count(aldex2.filtered.ngoatsWghtDist.3000m.sum$pearson.eBH < 0.1) # No ARG clusters are correlated significantly to nhorsesWghtDist.3000m.sum

# Could try with other exposure proxies but have chosen these based on previous beta-diversity results and logic.
```
# LUR and RF-modelled exposures 
## Preparing data - unfiltered
```{r}
# Since the DESeq2 function requires count data which has not been corrected for gene length, I need to create a new ps object with only corrections for volume input and qPCR bacterial count
# This ps object is just corrected for volume inputs
merged.rar3 <- readRDS("../Input_files/merged.rar3.rds")
metafile  <- "../Input_files/VGOCOPD_metadata_completed_20210429alx_correctFormulaColumnTU.xlsx.tab"
argmappingfile  <- "../Input_files/02e_TotalResfinderMapped_v3.tab"

metadata <- read.csv( metafile, header=TRUE, sep="\t", row.names=1 )
metadata
ARG.long <- read.csv( argmappingfile, header=TRUE, sep="\t")
head(ARG.long)

# We now want to correct for qPCR bacterial counts, but we don't want to correct for gene length. 
# create a list of sample ID and associated 16S qPCR count
qPCRcounts <- data.frame("SampleID"= unique(ARG.long$SampleName), "qPCR16S"= metadata$qPCR_16S_ngml)
rownames(qPCRcounts) <- NULL
qPCRcounts <- qPCRcounts %>% column_to_rownames("SampleID")

# convert otu values directly by matrix manipulation in the ps object using qPCRcounts data frame 
ps.for.DA <- merged.rar3
ps.for.DA@otu_table@.Data <- ps.for.DA@otu_table@.Data / qPCRcounts [ 1:73 ,]

# checks
ps.for.DA
head(taxa_names(ps.for.DA))
ps.for.DA@otu_table@.Data

# There was an error in the choice and labelling of 1 control sample and we ended up with the same control sample being used for 2 case samples. It was mislabelled as '13674' hence was thought to be a different sample to '13764' which was already included in the dataset. Therefore we must remoce '13674' from the dataset. 
ps.for.DA <- prune_samples(sample_names(ps.for.DA) != "13674", ps.for.DA) 
ps.for.DA
# Final PS object therefore now has 72 samples in total (35 cases, 34 controls, 3 blanks)

# Agglomerate at 90% cluster level
# Using the functions created by AB, I will now agglomerate the data to AMRcluster level - i.e. merge ARGs which are in the same ARGcluster (90% identity level)  
# Clustering of ARGs at the 90% identity level is classified as 'ARGCluster' in the tax data of the Final.ps object - agglomerate at this level i.e. create a new ps object with cluster 90 as default. Automatic default is the ARG level but this may not be very accurate therefore best to use cluster90 level (ARGCluster in ps object). 

# Tax_glom2 function as created by AB - save this in the global environment for later use
tax_glom2 <- function(physeq, taxrank=rank_names(physeq)[1],
                     NArm=TRUE, bad_empty=c(NA, "", " ", "\t")){
  #### This part is identical to phyloseq's tax_glom
  # Error if tax_table slot is empty
  if( is.null(access(physeq, "tax_table")) ){
    stop("The tax_glom2() function requires that physeq contain a taxonomyTable")
  }
  # Error if bad taxrank
  if( !taxrank[1] %in% rank_names(physeq) ){
    stop("Bad taxrank argument. Must be among the values of rank_names(physeq)")
  }
  # Make a vector from the taxonomic data.
  CN  <- which( rank_names(physeq) %in% taxrank[1] )
  tax <- as(access(physeq, "tax_table"), "matrix")[, CN]
  # if NArm is TRUE, remove the empty, white-space, NA values from
  if( NArm ){
    keep_species <- names(tax)[ !(tax %in% bad_empty) ]
    physeq <- prune_taxa(keep_species, physeq)
  }
  # Concatenate data up to the taxrank column, use this for agglomeration
  tax <- as(access(physeq, "tax_table"), "matrix")[, 1:CN, drop=FALSE]
  tax <- apply(tax, 1, function(i){paste(i, sep=";_;", collapse=";_;")})
  #### **Speedyseq changes start here**
  ## Make the new OTU table
  # Work with taxa as rows
  if (!taxa_are_rows(physeq)) {
    physeq <- phyloseq::t(physeq)
    # Note that we need to flip back to samples as rows at the end
    needs_flip <- TRUE
  } else {
    needs_flip <- FALSE
  }
  # Starting point is a tibble with rows as taxa, to be able to combine taxa
  # with the dplyr::summarize_*() functions
  otu <- otu_table(physeq)
  tb <- otu %>%
    as("matrix") %>%
    tibble::as_tibble(rownames = "OTU")
  # We want to name each new taxon (group of merged OTUs) by its "archetype",
  # the most abundant OTU in the group
  tb <- tb %>%
    tibble::add_column(Tax = tax, Sum = taxa_sums(physeq)) %>%
    dplyr::group_by(Tax)
  # Name new taxa by the most abundant OTU; pick the first OTU in case of
  # ties (to be consistent with phyloseq)
  new_taxa_names <- tb %>%
    dplyr::top_n(1, Sum) %>%
    dplyr::slice(1) %>%
    dplyr::select(Tax, OTU)
  # Sum abundances and rename taxa
  tb0 <- tb %>%
    dplyr::summarize_at(dplyr::vars(sample_names(physeq)), sum) %>%
    dplyr::left_join(new_taxa_names, by = "Tax") %>%
    dplyr::select(OTU, dplyr::everything(), -Tax)
  # Put back into phyloseq form
  mat <- tb0 %>%
    dplyr::select(-OTU) %>%
    as("matrix")
  rownames(mat) <- tb0$OTU
  otu0 <- otu_table(mat, taxa_are_rows = TRUE)
  ## Make the new phyloseq object
  # Replacing the original otu_table with the new, smaller table will
  # automatically prune the taxonomy, tree, and refseq to the smaller set of
  # archetypal otus
  otu_table(physeq) <- otu0
  # "Empty" the taxonomy values to the right of the rank, using
  # NA_character_.
  if (CN < length(rank_names(physeq))) {
    bad_ranks <- seq(CN + 1, length(rank_names(physeq)))
    tax_table(physeq)[, bad_ranks] <- NA_character_
  }
  ## Return.
  if (needs_flip) {
    physeq <- phyloseq::t(physeq)
  }
  return(physeq)
}

# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
ps.for.DA.aggl <- tax_glom2(ps.for.DA, taxrank=rank_names(ps.for.DA)[6], NArm=TRUE)
taxa_names(ps.for.DA.aggl)

# How many taxa before/after agglomeration?
ntaxa(ps.for.DA); ntaxa(ps.for.DA.aggl)

# How many taxa before/after agglomeration?
ntaxa(ps.for.DA); ntaxa(ps.for.DA.aggl) # 85 ARGClusters vs 233 ARGs 

# Now remove the blanks from this ps object
sam.data.noblanks <- subset(sample_data(ps.for.DA.aggl), !(row.names(sample_data(ps.for.DA.aggl)) %in% c("veldbl16", "veldbl3", "veldbl5")))
# Remove corresponding data from the phyloseq object
ps.for.DA.aggl.noblanks <- prune_samples(sample_names(sam.data.noblanks), ps.for.DA.aggl)

# Now add new sample data with exposure estimates from modelling
ps.for.DA.aggl.noblanks.expmodels <- ps.for.DA.aggl.noblanks
sam.data.new <- as.data.frame(sample_data(LUR_RF_residential_predictions))
sample_data(ps.for.DA.aggl.noblanks.expmodels) <- sam.data.new
ps.for.DA.aggl.noblanks.expmodels@sam_data
taxa_names(ps.for.DA.aggl.noblanks.expmodels)
```
## Preparing data - filtered
```{r}
# Filter- 0.1% relative abundance, 15% prevalent
# Create prevalence-abundance filter
# 0.1% abundant, 15% prevalent: Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
pres_abund_filter_deseq <- function(ps.for.DA.aggl.noblanks.expmodels, pres=10.35, abund=0.001) { # Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
filter_taxa(ps.for.DA.aggl.noblanks.expmodels, function(x) sum(x >= abund)>=pres, TRUE) }
# apply filter
ps.for.DA.aggl.noblanks.expmodels.filtered <- transform_sample_counts(ps.for.DA.aggl.noblanks.expmodels, function(x) x/sum(x) *100 ) %>% pres_abund_filter_deseq()
taxa_names(ps.for.DA.aggl.noblanks.expmodels.filtered)
# The apostrophes in the taxa names got lost in the agglomeration step and also the 'taxa_names' are not the ARGcluster names. The lowest level is the ARG cluster (the lower ranks are NA). However, the taxon name is the "wrong" accession name. 
# I rename the taxa based on the ARG cluster to which it corresponds.
taxa_names_ARGCluster <- as.data.frame(ps.for.DA.aggl.noblanks.expmodels.filtered@tax_table)[, "ARGCluster"]
colnames(ps.for.DA.aggl.noblanks.expmodels.filtered@otu_table) <- taxa_names_ARGCluster
# Verify the changes
taxa_names(otu_table(ps.for.DA.aggl.noblanks.expmodels.filtered))
# This is the final ps object to be used for DA analysis. It has been volume corrected, corrected for qPCR counts, agglomerated at 90% identity level and filtered so that taxa which are more than 0.1% abundant in more than 15% of samples are kept. 
ps.for.DA.aggl.noblanks.expmodels.filtered
# Check parts of the ps object to ensure all ok
ps.for.DA.aggl.noblanks.expmodels.filtered@otu_table # 30 taxa (agglomerated and filtered and named by the ARGCluster name)
ps.for.DA.aggl.noblanks.expmodels.filtered@sam_data # 69 sammples (no blanks - 35 copd cases and 34 controls)
ps.for.DA.aggl.noblanks.expmodels.filtered@tax_table # Contains information on 30 taxa
# Save this ps object
saveRDS(ps.for.DA.aggl.noblanks.expmodels.filtered, "../Output_files/ps.for.DA.aggl.noblanks.expmodels.filtered.rds")
taxa_names(ps.for.DA.aggl.noblanks.expmodels.filtered)
```
## DESeq2
### DESeq2
```{r}
# Determining exposure effects on ARG expression 
# The differential abundance (DA) analysis using DESeq2 aims to identify features (such as taxa) that show statistically significant differences in their abundance across different levels of the continuous predictor variables (the modelled exposures). The analysis provides insight into how the abundance of these features varies in response to changes in the continuous variable.
# All estimates are continuous variables
# Now ready to run the deseq2 analysis using the phyloseq_to_deseq2 function
Deseq_ps <- ps.for.DA.aggl.noblanks.expmodels.filtered
# E.coli LUR modelled concentrations 
# Convert phyloseq data to DESeq2 dataset object
deseq2.ecoliLUR <- phyloseq_to_deseq2(Deseq_ps,~E.coli_LUR_estimates)
# Run DESeq function 
deseq2.ecoliLUR <- DESeq(deseq2.ecoliLUR)
deseq2.ecoliLUR.results<- results(deseq2.ecoliLUR)
deseq2.ecoliLUR.results
# The log2 fold change represents the change in taxa abundance associated with a one-unit increase in E.coli_LUR_estimates values. If LFC is positive, it means that with a 1 unit increase in E.coli_LUR_estimates concentration, the abundance increases on a log2 scale. If negative then a 1 unit change is associated with decreases in abundance. 
# summary of differential gene expression
summary(deseq2.ecoliLUR.results)
# 23 out of 30 taxa have 'nonzero total read count' - this means that for 7 taxa the count data is extremely low whcih affects the ability to perform meaningful statistical analysis. 
# Adjusted p-value < 0.1: This indicates the number and percentage of features for which the adjusted p-value (padj) is less than 0.1. These are features that are potentially showing some level of association with the predictor variable (E.coli_LUR_estimates). The adjusted p-value takes into account multiple testing correction to control the false discovery rate.
# LFC > 0 (up): 0, 0%: This shows that none of the features are identified as having a positive log2 fold change (upregulated) at a significance level where the adjusted p-value is less than 0.1.
# LFC < 0 (down): 0, 0% Similarly, none of the features are identified as having a negative log2 fold change (downregulated) at a significance level where the adjusted p-value is less than 0.1.
# outliers [1]: 0, 0% This is indicating that no features are identified as outliers based on the Cook's distance metric.
# Among the 30 ARGs analysed, none are showing significant differential abundance based on the adjusted p-values and log2 fold changes in relation to the continuous predictor variable E.coli_LUR_estimates.
sum(deseq2.ecoliLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Staph LUR modelled concentrations 
deseq2.staphLUR <- phyloseq_to_deseq2(Deseq_ps,~Staph_LUR_estimates)
deseq2.staphLUR <- DESeq(deseq2.staphLUR)
deseq2.staphLUR.results<- results(deseq2.staphLUR)
deseq2.staphLUR.results
sum(deseq2.staphLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# tetW LUR modelled concentrations 
deseq2.tetWLUR <- phyloseq_to_deseq2(Deseq_ps,~tetW_LUR_estimates)
deseq2.tetWLUR <- DESeq(deseq2.tetWLUR)
deseq2.tetWLUR.results<- results(deseq2.tetWLUR)
deseq2.tetWLUR.results
sum(deseq2.tetWLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# mecA LUR modelled concentrations 
deseq2.mecALUR <- phyloseq_to_deseq2(Deseq_ps,~ mecA_LUR_estimates)
deseq2.mecALUR <- DESeq(deseq2.mecALUR)
deseq2.mecALUR.results<- results(deseq2.mecALUR)
deseq2.mecALUR.results
sum(deseq2.mecALUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# E.coli RF modelled concentrations
deseq2.ecoliRF <- phyloseq_to_deseq2(Deseq_ps,~ E.coli_RF_predictions)
deseq2.ecoliRF <- DESeq(deseq2.ecoliRF)
deseq2.ecoliRF.results<- results(deseq2.ecoliRF)
deseq2.ecoliRF.results
sum(deseq2.ecoliRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Staph RF modelled concentrations 
deseq2.staphRF <- phyloseq_to_deseq2(Deseq_ps,~ Staph_RF_predictions)
deseq2.staphRF <- DESeq(deseq2.staphRF)
deseq2.staphRF.results<- results(deseq2.staphRF)
deseq2.staphRF.results
sum(deseq2.staphRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# tetW RF modelled concentrations 
deseq2.tetWRF <- phyloseq_to_deseq2(Deseq_ps,~ tetW_RF_predictions)
deseq2.tetWRF <- DESeq(deseq2.tetWRF)
deseq2.tetWRF.results<- results(deseq2.tetWRF)
deseq2.tetWRF.results
sum(deseq2.tetWRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# mecA RF modelled concentrations 
deseq2.mecARF <- phyloseq_to_deseq2(Deseq_ps,~ tetW_RF_predictions)
deseq2.mecARF <- DESeq(deseq2.mecARF)
deseq2.mecARF.results<- results(deseq2.mecARF)
deseq2.mecARF.results
sum(deseq2.mecARF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Save results tables as excel files 
write.csv(deseq2.ecoliLUR.results, "../Output_files/DESeq_results/deseq2.ecoliLUR.results.csv")
write.csv(deseq2.staphLUR.results, "../Output_files/DESeq_results/deseq2.staphLUR.results.csv")
write.csv(deseq2.tetWLUR.results, "../Output_files/DESeq_results/deseq2.tetWLUR.results.csv")
write.csv(deseq2.mecALUR.results, "../Output_files/DESeq_results/deseq2.mecALUR.results.csv")
write.csv(deseq2.ecoliRF.results, "../Output_files/DESeq_results/deseq2.ecoliRF.results.csv")
write.csv(deseq2.staphRF.results, "../Output_files/DESeq_results/deseq2.staphRF.results.csv")
write.csv(deseq2.tetWRF.results, "../Output_files/DESeq_results/deseq2.tetWRF.results.csv")
write.csv(deseq2.mecARF.results, "../Output_files/DESeq_results/deseq2.mecARF.results.csv")

# Visualising results from DA analysis
# Create the volcano plot with log-scaled y-axis
volcano_plot_ecoliLUR <- ggplot(ecoliLUR_df, aes(x = log2FoldChange, y = -log10(padj))) +
  geom_point(aes(color = ifelse(padj < 0.1, "Significant", "Non-Significant")), alpha = 0.6) +
  labs(title = "Volcano Plot",
       x = "log2 Fold Change",
       y = "-log10(Adjusted p-value)") +
  theme_minimal() +
  geom_hline(yintercept = -log10(0.1), linetype = "dotted", color = "grey") +
  scale_color_manual(values = c("Significant" = "black", "Non-Significant" = "grey")) +
  scale_y_continuous(trans = "log10")  # Use log10 scale for y-axis

# Print the plot
print(volcano_plot_ecoliLUR)
```

## ALDEx2
```{r}
# copy over the previously agglomerated and filtered ps object from my above DESeq2 analysis
ALDEx.expmodels.ps <- ps.for.DA.aggl.noblanks.expmodels.filtered
tax_table(ALDEx.expmodels.ps) # 30 ARG Clusters 
ALDEx.expmodels.ps@sam_data # sample data contains all the modelled predictions for each participant

# create otu table for aldex2 analysis - this needs to be "A non-negative, integer-only data.frame or matrix with unique names for all rows and columns. Rows should contain genes and columns should contain sequencing read counts (i.e., sample vectors). Rows with 0 reads in each sample are deleted prior to analysis
ALDEx.expmodels.otutable <- t(otu_table(ALDEx.expmodels.ps))
ALDEx.expmodels.otutable <- round(ALDEx.expmodels.otutable * 1000000000,0) # Multiply by billion as aldex2 requires that reads are all integers 
ALDEx.expmodels.otutable <- data.frame(ALDEx.expmodels.otutable)

# Firstly create the aldex.clr object
ALDEx2.expmodels.clr <- aldex.clr(ALDEx.expmodels.otutable, mc.samples = 128, verbose = FALSE, useMC=FALSE)

# LUR modelled E. coli 
ALDEx.expmodels.E.coli_LUR_estimates <- sample_data(ALDEx.expmodels.ps)$E.coli_LUR_estimates
ALDEx.expmodels.E.coli_LUR_estimates <- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.E.coli_LUR_estimates)
ALDEx.expmodels.E.coli_LUR_estimates
ALDEx.expmodels.E.coli_LUR_estimates <- ALDEx.expmodels.E.coli_LUR_estimates[order(ALDEx.expmodels.E.coli_LUR_estimates$pearson.eBH),]
count(ALDEx.expmodels.E.coli_LUR_estimates$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# LUR modelled Staph
ALDEx.expmodels.Staph_LUR_estimates <- sample_data(ALDEx.expmodels.ps)$Staph_LUR_estimates
ALDEx.expmodels.Staph_LUR_estimates <- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.Staph_LUR_estimates)
ALDEx.expmodels.Staph_LUR_estimates
count(ALDEx.expmodels.Staph_LUR_estimates$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# LUR modelled tetW
ALDEx.expmodels.tetW_LUR_estimates <- sample_data(ALDEx.expmodels.ps)$tetW_LUR_estimates
ALDEx.expmodels.tetW_LUR_estimates<- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.tetW_LUR_estimates)
ALDEx.expmodels.tetW_LUR_estimates
count(ALDEx.expmodels.tetW_LUR_estimates$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# LUR modelled mecA
ALDEx.expmodels.mecA_LUR_estimates <- sample_data(ALDEx.expmodels.ps)$mecA_LUR_estimates
ALDEx.expmodels.mecA_LUR_estimates<- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.mecA_LUR_estimates)
ALDEx.expmodels.mecA_LUR_estimates
count(aldex2.filtered.ngoatsWghtDist.3000m.sum$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1 nhorsesWghtDist.3000m.sum

# RF modelled E. coli 
ALDEx2.expmodels.clr
ALDEx.expmodels.E.coli_RF_predictions <- sample_data(ALDEx.expmodels.ps)$E.coli_RF_predictions
ALDEx.expmodels.E.coli_RF_predictions <- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.E.coli_RF_predictions)
ALDEx.expmodels.E.coli_RF_predictions
count(ALDEx.expmodels.E.coli_RF_predictions$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# RF modelled Staph
ALDEx.expmodels.Staph_RF_predictions <- sample_data(ALDEx.expmodels.ps)$Staph_RF_predictions
ALDEx.expmodels.Staph_RF_predictions <- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.Staph_LUR_estimates)
ALDEx.expmodels.Staph_RF_predictions
count(ALDEx.expmodels.Staph_RF_predictions$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# RF modelled tetW
ALDEx.expmodels.tetW_RF_predictions <- sample_data(ALDEx.expmodels.ps)$tetW_RF_predictions
ALDEx.expmodels.tetW_RF_predictions<- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.tetW_RF_predictions)
ALDEx.expmodels.tetW_RF_predictions
count(ALDEx.expmodels.tetW_LUR_estimates$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1

# RF modelled mecA
ALDEx.expmodels.mecA_RF_predictions <- sample_data(ALDEx.expmodels.ps)$mecA_RF_predictions
ALDEx.expmodels.mecA_RF_predictions <- aldex.corr(ALDEx2.expmodels.clr, ALDEx.expmodels.mecA_LUR_estimates)
ALDEx.expmodels.mecA_RF_predictions
count(ALDEx.expmodels.mecA_RF_predictions$pearson.eBH < 0.1) # No ARG clusters have an expected Benjamini-Hochberg corrected P-value of the Pearson Product moment value < 0.1 nhorsesWghtDist.3000m.sum
```