---
title: "LUR and RF models and the resistome"
output: html_notebook
---
# Packages and data
```{r}
library(openxlsx)
library(purr)
library(gtools)
library(lattice)
library(vegan)
library(car)
library(olsrr)
library(stats)
library(phyloseq)
library(dplyr)
library(tidyr)
library(textshape)
library(tibble)
library(openxlsx)
library(BiocManager)
BiocManager::install("DESeq2") # For DA analysis - DESeq2 is available through Bioconductor.Bioconductor packages need to be installed using the BiocManager package to ensure compatibility and proper functionality with other Bioconductor packages.
library(DESeq2)
getwd()
# Import the LUR and RF estimates of E.coli, staph, tetW and mecA concentrations for each of the 69 participant
# SLR LUR-modelled E.coli, staph, tetW and mecA concentrations
LUR_RF_residential_predictions  <- read.xlsx("Output_files//LUR_RF_residential_predictions.xlsx")

LUR_RF_residential_predictions <- data.frame(LUR_RF_residential_predictions, row.names = LUR_RF_residential_predictions$X1)
LUR_RF_residential_predictions$X1 <- NULL 
```
# Descriptives of participant microbial estimates
```{r}
# Compute the mean for each exposure estimate
mean_values <- colMeans(LUR_RF_residential_predictions)

# Compute the standard deviation (SD) for each exposure estimate
sd_values <- apply(LUR_RF_residential_predictions, 2, sd)

# Compute the median for each exposure estimate
median_values <- apply(LUR_RF_residential_predictions, 2, median)

# Compute the 25th percentile for each exposure estimate
percentile_25_values <- apply(LUR_RF_residential_predictions, 2, quantile, probs = 0.25)

# Compute the 75th percentile for each exposure estimate
percentile_75_values <- apply(LUR_RF_residential_predictions, 2, quantile, probs = 0.75)

# Compute the minimum value for each exposure estimate 
min_values <- apply(LUR_RF_residential_predictions, 2, min)

# Compute the maximum value for each exposure estimate
max_values <- apply(LUR_RF_residential_predictions, 2, max)

# Combine the results into a new DataFrame for better visualization
summary_statistics_df <- data.frame(
  Mean = mean_values,
  SD = sd_values,
  Median = median_values,
  `25th Percentile` = percentile_25_values,
  `75th Percentile` = percentile_75_values,
  Minimum = min_values,
  Maximum = max_values
)

# Display the summary statistics
print(summary_statistics_df)
write.xlsx(summary_statistics_df, "Output_files//summary_statistics_df_residential_modelled_exp.xlsx")

# Check distribution of modelled concentrations
hist(LUR_RF_residential_predictions$E.coli_LUR_estimates)
hist(LUR_RF_residential_predictions$Staph_LUR_estimates)
hist(LUR_RF_residential_predictions$tetW_LUR_estimates)
hist(LUR_RF_residential_predictions$mecA_LUR_estimates)

hist(LUR_RF_residential_predictions$E.coli_RF_predictions)
hist(LUR_RF_residential_predictions$Staph_RF_predictions)
hist(LUR_RF_residential_predictions$tetW_RF_predictions)
hist(LUR_RF_residential_predictions$mecA_RF_predictions)

# FOR PRESENTATION SLIDES 
# Now I want to compute summary statistics per group i.e. for COPD and control separately
# this ss has the LUR and RF-modelled concentrations, pt IDs and copd status
LUR_RF_residential_predictions_copdstatus <- read.xlsx("Output_files//LUR_RF_residential_predictions_copdstatus.xlsx")

# Group data based on the 'copdcaco' column
copdcaco_grouped_data <- LUR_RF_residential_predictions_copdstatus %>%
  group_by(copdcaco)

# Compute the mean values within each group
grouped_mean_values <- copdcaco_grouped_data %>%
  summarize(mecA_RFmodelled_mean_value = mean(mecA_RF_predictions))
# Print the grouped mean values
print(grouped_mean_values)

# Now compute 
livestock_exposure_copdcaco <- read.csv("Input_files//VGOcopdcaco_resistome_Livestpred_forBea_copdstatus.csv")

# Group data based on the 'copdcaco' column
copdcaco_grouped_data_livestockpreds <- livestock_exposure_copdcaco %>%
  group_by(copdcaco)

# Compute the mean values within each group
grouped_mean_values_farms <- copdcaco_grouped_data_livestockpreds %>%
  summarize(AllFarm.3000m = mean(AllFarm.3000m))
# Print the grouped mean values
print(grouped_mean_values_farms)
```

# Alpha diversity
```{r}
# Alpha diversity - MULTIPLY BY BILLION METHOD
# The abundance data contains decimals as it has been corrected per gene length, therefore none are whole numbers. Observing the data I see that there are a maximum of 7 decimals in the dataset.
# Alpha diversity calculations require whole numbers...
# I will multiply by 1,000,000,000 in order to remove all these decimals to do the alpha diversity calculations. 
Final.ps.noblanks <- readRDS("C://Users//Cornu003//OneDrive - Universiteit Utrecht//Documents//Epidemiology MSc 2020//Research Project//ResCap//ResCap_2020_v4_rarefied//Final.ps.noblanks.rds")
Final.ps.noblanks@sam_data # we want to replace this current sample data in the ps object.

# copy over original ps object and create a new one
Final.ps.noblanks.LUR.RF.estimates <- Final.ps.noblanks
# Add the modelled exposure data to the ps object
sample_data(Final.ps.noblanks.LUR.RF.estimates) <- sample_data(LUR_RF_residential_predictions)
# Add the copdcaco status to the sample data of the ps object 
Final.ps.noblanks.LUR.RF.estimates@sam_data$copdcaco <- Final.ps.noblanks@sam_data$copdcaco 
# Check the ps sample data
Final.ps.noblanks.LUR.RF.estimates@sam_data

Final.ps.noblanks.LUR.RF.estimates.multiplybillion <- Final.ps.noblanks.LUR.RF.estimates
Final.ps.noblanks.LUR.RF.estimates.multiplybillion@otu_table@.Data <- (Final.ps.noblanks.LUR.RF.estimates.multiplybillion@otu_table@.Data)*1000000000
head(Final.ps.noblanks.LUR.RF.estimates.multiplybillion@otu_table@.Data)

# Create tables with alpha diversity measures
library(microbiome)
Shannon <- microbiome::alpha(Final.ps.noblanks.LUR.RF.estimates.multiplybillion, (index = "Shannon"), zeroes = TRUE)
Simpson_evenness <- microbiome::alpha(Final.ps.noblanks.LUR.RF.estimates.multiplybillion, (index = "simpson"), zeroes = TRUE)
Observed_richness <-  microbiome::alpha(Final.ps.noblanks.LUR.RF.estimates.multiplybillion, (index = "Observed"), zeroes = TRUE)
Simpson_evenness$evenness_simpson

#Now add the diversity tables to the metadata
sample_data(Final.ps.noblanks.LUR.RF.estimates.multiplybillion)$Shannon <- Shannon$diversity_shannon
sample_data(Final.ps.noblanks.LUR.RF.estimates.multiplybillion)$Simpson_Evenness <- Simpson_evenness$evenness_simpson
sample_data(Final.ps.noblanks.LUR.RF.estimates.multiplybillion)$Observed_richness <- Observed_richness$observed

#check whether this has been added to the metadata table
sample_data(Final.ps.noblanks.LUR.RF.estimates.multiplybillion) # YES

LUR_RF_exposure_alphadiversity_df <- as.data.frame(Final.ps.noblanks.LUR.RF.estimates.multiplybillion@sam_data)

# Alpha diversity with the LUR-modelled concentrations
lm_shannon_E.coli_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$E.coli_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_Staph_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$Staph_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_tetW_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$tetW_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_mecA_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$mecA_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)

lm_simpeveness_E.coli_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$E.coli_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_Staph_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$Staph_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_tetW_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$tetW_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_mecA_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$mecA_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)

lm_observed_E.coli_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$E.coli_LUR_estimates+ LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_Staph_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$Staph_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_tetW_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$tetW_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_mecA_LUR <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$mecA_LUR_estimates + LUR_RF_exposure_alphadiversity_df$copdcaco)

summary(lm_shannon_E.coli_LUR)
summary(lm_shannon_Staph_LUR)
summary(lm_shannon_tetW_LUR)
summary(lm_shannon_mecA_LUR)

summary(lm_simpeveness_E.coli_LUR)
summary(lm_simpeveness_Staph_LUR)
summary(lm_simpeveness_tetW_LUR)
summary(lm_simpeveness_mecA_LUR)

summary(lm_observed_E.coli_LUR)
summary(lm_observed_Staph_LUR)
summary(lm_observed_tetW_LUR)
summary(lm_observed_mecA_LUR)

# Alpha diversity with the RF-modelled concentrations
lm_shannon_E.coli_RF <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$E.coli_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_Staph_RF <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$Staph_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_tetW_RF <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$tetW_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_shannon_mecA_RF <- lm(LUR_RF_exposure_alphadiversity_df$Shannon~LUR_RF_exposure_alphadiversity_df$mecA_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)

lm_simpeveness_E.coli_RF <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$E.coli_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_Staph_RF <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$Staph_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_tetW_RF <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$tetW_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_simpeveness_mecA_RF <- lm(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness~LUR_RF_exposure_alphadiversity_df$mecA_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)

lm_observed_E.coli_RF <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$E.coli_RF_predictions+ LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_Staph_RF <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$Staph_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_tetW_RF <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$tetW_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)
lm_observed_mecA_RF <- lm(LUR_RF_exposure_alphadiversity_df$Observed~LUR_RF_exposure_alphadiversity_df$mecA_RF_predictions + LUR_RF_exposure_alphadiversity_df$copdcaco)

summary(lm_shannon_E.coli_RF)
summary(lm_shannon_Staph_RF)
summary(lm_shannon_tetW_RF)
summary(lm_shannon_mecA_RF)

summary(lm_simpeveness_E.coli_RF)
summary(lm_simpeveness_Staph_RF)
summary(lm_simpeveness_tetW_RF)
summary(lm_simpeveness_mecA_RF)

summary(lm_observed_E.coli_RF)
summary(lm_observed_Staph_RF)
summary(lm_observed_tetW_RF)
summary(lm_observed_mecA_RF)

# Combine all linear regression models into one dataframe
All_LUR_RF_models <- list(lm_shannon_E.coli_LUR, lm_shannon_Staph_LUR, lm_shannon_tetW_LUR, lm_shannon_mecA_LUR, lm_simpeveness_E.coli_LUR, lm_simpeveness_Staph_LUR, lm_simpeveness_tetW_LUR, lm_simpeveness_mecA_LUR, lm_observed_E.coli_LUR, lm_observed_Staph_LUR, lm_observed_tetW_LUR, lm_observed_mecA_LUR,lm_shannon_E.coli_RF, lm_shannon_Staph_RF, lm_shannon_tetW_RF, lm_shannon_mecA_RF, lm_simpeveness_E.coli_RF, lm_simpeveness_Staph_RF, lm_simpeveness_tetW_RF, lm_simpeveness_mecA_RF, lm_observed_E.coli_RF, lm_observed_Staph_RF, lm_observed_tetW_RF, lm_observed_mecA_RF)
# Print results of all regression models
combined_results <- map_dfr(All_LUR_RF_models, tidy)
write.csv(combined_results, file = "Output_files//Alpha_diversity_LUR_RF_microbial_exposure_results.csv", row.names = FALSE)

# Assumption checking
# Checking assumptions of multiple linear regression models
# The four key assumptions are: Linearity of the relationship between y and its explanatory variables, Independence of variables where explanatory variables are not highly correlated with each other, Normal distribution of residuals, Homoscedasticity or equal variance of residuals
library(ggplot2)
library(corrplot)
library(car)
library(magrittr)

# R has a set of built in regression diagnostic plots (4 in total) set of diagnostics plots
# Checking assumptions of simple linear regression models
{par(mfrow= c(2,2))
plot( lm_shannon_E.coli_LUR)
plot( lm_shannon_Staph_LUR)
plot( lm_shannon_tetW_LUR)
plot( lm_shannon_mecA_LUR)
plot( lm_simpeveness_E.coli_LUR)
plot( lm_simpeveness_Staph_LUR)
plot( lm_simpeveness_tetW_LUR)
plot( lm_simpeveness_mecA_LUR)
plot( lm_observed_E.coli_LUR)
plot( lm_observed_Staph_LUR)
plot( lm_observed_tetW_LUR)
plot( lm_observed_mecA_LUR)
plot( lm_shannon_E.coli_RF)
plot( lm_shannon_Staph_RF)
plot( lm_shannon_tetW_RF)
plot( lm_shannon_mecA_RF)
plot( lm_simpeveness_E.coli_RF)
plot( lm_simpeveness_Staph_RF)
plot( lm_simpeveness_tetW_RF)
plot( lm_simpeveness_mecA_RF)
plot( lm_observed_E.coli_RF)
plot( lm_observed_Staph_RF)
plot( lm_observed_tetW_RF)
plot( lm_observed_mecA_RF)}

# Durbin watson test is used to detect the presence of autocorrelation in the residuals
library(car)
durbinWatsonTest( lm_shannon_E.coli_LUR)
durbinWatsonTest( lm_shannon_Staph_LUR)
durbinWatsonTest( lm_shannon_tetW_LUR)
durbinWatsonTest( lm_shannon_mecA_LUR)
durbinWatsonTest( lm_simpeveness_E.coli_LUR)
durbinWatsonTest( lm_simpeveness_Staph_LUR)
durbinWatsonTest( lm_simpeveness_tetW_LUR)
durbinWatsonTest( lm_simpeveness_mecA_LUR)
durbinWatsonTest( lm_observed_E.coli_LUR)
durbinWatsonTest( lm_observed_Staph_LUR)
durbinWatsonTest( lm_observed_tetW_LUR)
durbinWatsonTest( lm_observed_mecA_LUR)
durbinWatsonTest( lm_shannon_E.coli_RF)
durbinWatsonTest( lm_shannon_Staph_RF)
durbinWatsonTest( lm_shannon_tetW_RF)
durbinWatsonTest( lm_shannon_mecA_RF)
durbinWatsonTest( lm_simpeveness_E.coli_RF)
durbinWatsonTest( lm_simpeveness_Staph_RF)
durbinWatsonTest( lm_simpeveness_tetW_RF)
durbinWatsonTest( lm_simpeveness_mecA_RF)
durbinWatsonTest( lm_observed_E.coli_RF)
durbinWatsonTest( lm_observed_Staph_RF)
durbinWatsonTest( lm_observed_tetW_RF)
durbinWatsonTest( lm_observed_mecA_RF)
# None significant - no significant autocorrelation detected

# Cook's distance 
which(cooks.distance( lm_shannon_E.coli_LUR)>1)
which(cooks.distance(lm_shannon_Staph_LUR)>1)
which(cooks.distance( lm_shannon_tetW_LUR)>1)
which(cooks.distance( lm_shannon_mecA_LUR)>1)
which(cooks.distance( lm_simpeveness_E.coli_LUR)>1)
which(cooks.distance( lm_simpeveness_Staph_LUR)>1)
which(cooks.distance( lm_simpeveness_tetW_LUR)>1)
which(cooks.distance( lm_simpeveness_mecA_LUR)>1)
which(cooks.distance( lm_observed_E.coli_LUR)>1)
which(cooks.distance( lm_observed_Staph_LUR)>1)
which(cooks.distance( lm_observed_tetW_LUR)>1)
which(cooks.distance( lm_observed_mecA_LUR)>1)
which(cooks.distance( lm_shannon_E.coli_RF)>1)
which(cooks.distance( lm_shannon_Staph_RF)>1)
which(cooks.distance( lm_shannon_tetW_RF)>1)
which(cooks.distance( lm_shannon_mecA_RF)>1)
which(cooks.distance( lm_simpeveness_E.coli_RF)>1)
which(cooks.distance( lm_simpeveness_Staph_RF)>1)
which(cooks.distance( lm_simpeveness_tetW_RF)>1)
which(cooks.distance( lm_simpeveness_mecA_RF)>1)
which(cooks.distance( lm_observed_E.coli_RF)>1)
which(cooks.distance( lm_observed_Staph_RF)>1)
which(cooks.distance( lm_observed_tetW_RF)>1)
which(cooks.distance( lm_observed_mecA_RF)>1)
# No cook's distances > 1 - no serious outliers

# Extract the slope coefficient and p-value from the linear regression model
slope_coef_simp_staph <- coef(lm_simpeveness_Staph_LUR)[2]
names(slope_coef_simp_staph) <- NULL
p_value_simp_staph <- summary(lm_simpeveness_Staph_LUR)$coefficients[2, 4]

# Create the ggplot object with your data
staphLUR_simpson_plot <- ggplot(LUR_RF_exposure_alphadiversity_df, aes(x = Staph_LUR_estimates, y = Simpson_Evenness)) +
  # Customize the scatterplot points
  geom_point(size = 4, color = "blue", alpha = 0.7) +
  # Add a regression line
  geom_abline(intercept = coef(lm_simpeveness_Staph_LUR)[1], slope = coef(lm_simpeveness_Staph_LUR)[2],
              color = "red", linetype = "dashed", linewidth = 1.5) +
  # Add slope coefficient and p-value as annotations
  geom_text(x = max(LUR_RF_exposure_alphadiversity_df$Staph_LUR_estimates), y = max(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness)-0.03,
            label = paste("Slope coefficient =", round(slope_coef_simp_staph, 3)), color = "red", size = 4, hjust = 1, vjust = 1) +
  geom_text(x = max(LUR_RF_exposure_alphadiversity_df$Staph_LUR_estimates), y = max(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness) - 0.05,
            label = paste("p-value =", signif(p_value_simp_staph, digits = 3)), color = "red", size = 4, hjust = 1, vjust = 1) +
  # Customize x and y axis labels and title
  labs(x = "Residential exposure to Staphylococcus (LUR-modelled) (gene copies/m^2)", y = "Simpson's Evenness index",
       title = bquote(atop("Simpson's Evenness index vs. " * italic("Staphylococcus") * "exposure estimates"))) +
  # Customize the theme (adjust the appearance of the plot)
  theme_minimal() +
  theme(plot.title = element_text(size = 14),
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 14))

# Print the plot
print(staphLUR_simpson_plot)


# Assuming you have already calculated the linear regression model
# lm_simpeveness_mecA_RF <- lm(Simpson_Evenness ~ mecA_RF_predictions, data = LUR_RF_exposure_alphadiversity_df)

# Extract the slope coefficient and p-value from the linear regression model
slope_coef <- coef(lm_simpeveness_mecA_RF)[2]
names(slope_coef) <- NULL
p_value <- summary(lm_simpeveness_mecA_RF)$coefficients[2, 4]

# Assuming you have already calculated the linear regression model
# lm_simpeveness_mecA_RF <- lm(Simpson_Evenness ~ mecA_RF_predictions, data = LUR_RF_exposure_alphadiversity_df)

# Extract the slope coefficient and p-value from the linear regression model
slope_coef <- coef(lm_simpeveness_mecA_RF)[2]
names(slope_coef) <- NULL
p_value <- summary(lm_simpeveness_mecA_RF)$coefficients[2, 4]

# Create the ggplot object with your data
mecA_simpson_plot <- ggplot(LUR_RF_exposure_alphadiversity_df, aes(x = mecA_RF_predictions, y = Simpson_Evenness)) +
  # Customize the scatterplot points
  geom_point(size = 4, color = "blue", alpha = 0.7) +
  # Add a regression line
  geom_abline(intercept = coef(lm_simpeveness_mecA_RF)[1], slope = coef(lm_simpeveness_mecA_RF)[2],
              color = "red", linetype = "dashed", linewidth = 1.5) +
  # Add slope coefficient and p-value as annotations
  geom_text(x = max(LUR_RF_exposure_alphadiversity_df$mecA_RF_predictions), y = max(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness)-0.03,
            label = paste("Slope coefficient =", round(slope_coef, 3)), color = "red", size = 4, hjust = 1, vjust = 1) +
  geom_text(x = max(LUR_RF_exposure_alphadiversity_df$mecA_RF_predictions), y = max(LUR_RF_exposure_alphadiversity_df$Simpson_Evenness) - 0.05,
            label = paste("p-value =", signif(p_value, digits = 3)), color = "red", size = 4, hjust = 1, vjust = 1) +
  # Customize x and y axis labels and title
  labs(x = "Residential exposure to mecA (RF-modelled) (gene copies/m^2)", y = "Simpson's Evenness index",
       title = bquote(atop("Simpson's Evenness index vs. " * italic("mec") * "A exposure estimates"))) +
  # Customize the theme (adjust the appearance of the plot)
  theme_minimal() +
  theme(plot.title = element_text(size = 14),
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 14))

# Print the plot
print(mecA_simpson_plot)





# For poster ERS
# Create a ggplot object with your data
mecA_simpson_plot <- ggplot(LUR_RF_exposure_alphadiversity_df, aes(x = mecA_RF_predictions, y = Simpson_Evenness)) +
  # Customize the scatterplot points
  geom_point(size = 4, color = "blue", alpha = 0.7) +
  # Add a regression line
  geom_abline(intercept = coef(lm_simpeveness_mecA_RF)[1], slope = coef(lm_simpeveness_mecA_RF)[2],
              color = "red", linetype = "dashed", linewidth = 1.5) +
  # Customize x and y axis labels and title
  labs(x = "Residential livestock-associated microbial emission", y = "Simpson Evenness diversity index",
       title = bquote(atop("Resistome alpha diversity vs. " * italic("mec") * "A exposure estimates"))) +
  # Set the aspect ratio to 1 (square plot)
  coord_fixed() +
  # Customize the theme (adjust the appearance of the plot)
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 16))

# Print the plot
print(mecA_simpson_plot)
```
# Beta diversity
## Ordinations
```{r}
# I will construct ordinations based on modelled microbial agent concentrations
# Read in the ps object which has been agglomerated at the 90% identity level - this was previously created in the script 'BCHRNotebook_20210605'
ARGcluster.aggl.noblanks <- readRDS("C://Users//Cornu003//OneDrive - Universiteit Utrecht//Documents//Epidemiology MSc 2020//Research Project//ResCap//ResCap_2020_v4_rarefied//ARGcluster.aggl.noblanks.rds")

ARGcluster.aggl.noblanks.LUR.RF.estimates <- ARGcluster.aggl.noblanks
sample_data(ARGcluster.aggl.noblanks.LUR.RF.estimates)

# Add the modelled exposure data to the ps object
sample_data(ARGcluster.aggl.noblanks.LUR.RF.estimates) <- sample_data(LUR_RF_residential_predictions)
# Add the copdcaco status to the sample data of the ps object 
ARGcluster.aggl.noblanks.LUR.RF.estimates@sam_data$copdcaco <- ARGcluster.aggl.noblanks@sam_data$copdcaco 
# Check the ps sample data
ARGcluster.aggl.noblanks.LUR.RF.estimates@sam_data


# PCoA 
# I will construct principal coordinates analysis based on Bray-Curtis dissimilarities. These measures are based on abundance or read count data. It generates differences in ARG abundances between two samples (e.g., at species level) which are from 0 to 1 (where 0= both samples share the same species at exactly the same abundances and 1= both samples have complete different species abundances).
# Firstly I need to categorise my exposure variables which are currently continuous numeric to quantiles (factor variables) - I want an equal % of variables in each quantile
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT <- ARGcluster.aggl.noblanks.LUR.RF.estimates
# I will use the quantcut() function in gtools -quantcut(x, q = 4, na.rm = TRUE, ...)
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_LUR_estimates, q=4, labels =c("1st quantile (E.coli_LUR_estimates)", "2nd quantile (E.coli_LUR_estimates)", "3rd quantile (E.coli_LUR_estimates)", "4th quantile (E.coli_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_LUR_estimates, q=4, labels =c("1st quantile (Staph_LUR_estimates)", "2nd quantile (Staph_LUR_estimates)", "3rd quantile (Staph_LUR_estimates)", "4th quantile (Staph_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_LUR_estimates, q=4, labels =c("1st quantile (tetW_LUR_estimates)", "2nd quantile (tetW_LUR_estimates)", "3rd quantile (tetW_LUR_estimates)", "4th quantile (tetW_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_LUR_estimates, q=4, labels =c("1st quantile (mecA_LUR_estimates)", "2nd quantile (mecA_LUR_estimates)", "3rd quantile (mecA_LUR_estimates)", "4th quantile (mecA_LUR_estimates)"))

ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_RF_predictions, q=4, labels =c("1st quantile (E.coli_RF_predictions)", "2nd quantile (E.coli_RF_predictions)", "3rd quantile (E.coli_RF_predictions)", "4th quantile (E.coli_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_RF_predictions, q=4, labels =c("1st quantile (Staph_RF_predictions)", "2nd quantile (Staph_RF_predictions)", "3rd quantile (Staph_RF_predictions)", "4th quantile (Staph_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_RF_predictions, q=4, labels =c("1st quantile (tetW_RF_predictions)", "2nd quantile (tetW_RF_predictions)", "3rd quantile (tetW_RF_predictions)", "4th quantile (tetW_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_RF_predictions, q=4, labels =c("1st quantile (mecA_RF_predictions)", "2nd quantile (mecA_RF_predictions)", "3rd quantile (mecA_RF_predictions)", "4th quantile (mecA_RF_predictions)"))

# PCoA on the BC dissimilarity matrix of the clustered resistome data (as before)
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA <- ordinate(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, method="PCoA", distance="bray")
# Extract the vectors from the PCoA 
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA$vectors # i.e. this tells us how much of the total variance is explained by each of the axes with respect to the total variance
# Show dominant eigen planes
plot_scree(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA)

# LUR-modelled E. coli
PCoA.plot.E.coli_LUR_estimates<- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "E.coli_LUR_estimates", shape="E.coli_LUR_estimates") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by E. coli exposure quantiles (LUR-modelled)") +
  labs(legend="E. coli (LUR-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = E.coli_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.E.coli_LUR_estimates
# Add ellipses 
PCoA.plot.E.coli_LUR_estimates + stat_ellipse()


# LUR-modelled Staph
PCoA.plot.Staph_LUR_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "Staph_LUR_estimates", shape="Staph_LUR_estimates") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by Staph spp. exposure quantiles (LUR-modelled)") +
  labs(legend="Staph (LUR-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = Staph_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.Staph_LUR_estimates
# Add ellipses 
PCoA.plot.Staph_LUR_estimates + stat_ellipse()

# LUR-modelled tetW
PCoA.plot.tetW_LUR_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "tetW_LUR_estimates", shape="tetW_LUR_estimates") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by tetW exposure quantiles (LUR-modelled)") +
  labs(legend="tetW (LUR-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = tetW_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.tetW_LUR_estimates
# Add ellipses 
PCoA.plot.tetW_LUR_estimates + stat_ellipse()


# LUR-modelled mecA
PCoA.plot.mecA_LUR_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "mecA_LUR_estimates", shape="mecA_LUR_estimates") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by mecA exposure quantiles (LUR-modelled)") +
  labs(legend="mecA (LUR-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = mecA_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.mecA_LUR_estimates
# Add ellipses 
PCoA.plot.mecA_LUR_estimates + stat_ellipse()

# RF-modelled E. coli
PCoA.plot.E.coli_RF_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "E.coli_RF_predictions", shape="E.coli_RF_predictions") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by E. coli exposure quantiles (RF-modelled)") +
  labs(legend="E. coli (RF-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = E.coli_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.E.coli_RF_estimates
# Add ellipses 
PCoA.plot.E.coli_RF_estimates + stat_ellipse()

# RF-modelled Staph
PCoA.plot.Staph_RF_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "Staph_RF_predictions", shape="Staph_RF_predictions") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by Staph exposure quantiles (RF-modelled)") +
  labs(legend="Staph (RF-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = Staph_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.Staph_RF_estimates
# Add ellipses 
PCoA.plot.Staph_RF_estimates + stat_ellipse()

# RF-modelled tetW
PCoA.plot.tetW_RF_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "tetW_RF_predictions", shape="tetW_RF_predictions") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by tetW exposure quantiles (RF-modelled)") +
  labs(legend="tetW (RF-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = tetW_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.tetW_RF_estimates
# Add ellipses 
PCoA.plot.tetW_RF_estimates + stat_ellipse()

ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_RF_predictions
ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA$
# RF-modelled mecA
PCoA.plot.mecA_RF_estimates <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT, ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT.PCoA, color = "mecA_RF_predictions", shape="mecA_RF_predictions") +
    ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by mecA exposure quantiles (RF-modelled)") +
  labs(legend="mecA (RF-modelled) exposure quantiles")+
    geom_point(size =5) +
    geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = mecA_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.mecA_RF_estimates
# Add ellipses 
PCoA.plot.mecA_RF_estimates + stat_ellipse()


## CUTTING EXPOSURE DATA INTO HALVES 
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES <- ARGcluster.aggl.noblanks.LUR.RF.estimates
# I will use the quantcut() function in gtools -quantcut(x, q = 4, na.rm = TRUE, ...)
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_LUR_estimates, q=2, labels =c("Top half (E.coli_LUR_estimates)", "Bottom half (E.coli_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_LUR_estimates, q=2, labels =c("Top half (Staph_LUR_estimates)", "Bottom half (Staph_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_LUR_estimates, q=2, labels =c("Top half (tetW_LUR_estimates)", "Bottom half (tetW_LUR_estimates)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_LUR_estimates<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_LUR_estimates, q=2, labels =c("Top half (mecA_LUR_estimates)", "Bottom half (mecA_LUR_estimates)"))

ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_RF_predictions, q=2, labels =c("Top half (E.coli_RF_predictions)", "Bottom half (E.coli_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_RF_predictions, q=2, labels =c("Top half (Staph_RF_predictions)", "Bottom half (Staph_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_RF_predictions, q=2, labels =c("Top half (tetW_RF_predictions)", "Bottom half (tetW_RF_predictions)"))
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_RF_predictions<-quantcut(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_RF_predictions, q=2, labels =c("Top half (mecA_RF_predictions)", "Bottom half (mecA_RF_predictions)"))

# PCoA on the BC dissimilarity matrix of the clustered resistome data (as before)
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA <- ordinate(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, method="PCoA", distance="bray")
# Extract the vectors from the PCoA 
ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA$vectors # i.e. this tells us how much of the total variance is explained by each of the axes with respect to the total variance
# Show dominant eigen planes
plot_scree(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA)

# LUR-modelled E. coli
PCoA.plot.E.coli_LUR_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "E.coli_LUR_estimates", shape="E.coli_LUR_estimates") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by E. coli exposure halves (LUR-modelled)") +
  labs(legend="E. coli (LUR-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = E.coli_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.E.coli_LUR_estimates_HALVES
# Add ellipses 
PCoA.plot.E.coli_LUR_estimates_HALVES + stat_ellipse()


# LUR-modelled Staph
PCoA.plot.Staph_LUR_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "Staph_LUR_estimates", shape="Staph_LUR_estimates") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by Staph spp. exposure halves (LUR-modelled)") +
  labs(legend="Staph (LUR-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = Staph_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.Staph_LUR_estimates_HALVES
# Add ellipses 
PCoA.plot.Staph_LUR_estimates_HALVES + stat_ellipse()

# LUR-modelled tetW
PCoA.plot.tetW_LUR_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "tetW_LUR_estimates", shape="tetW_LUR_estimates") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by tetW exposure halves (LUR-modelled)") +
  labs(legend="tetW (LUR-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = tetW_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.tetW_LUR_estimates_HALVES
# Add ellipses 
PCoA.plot.tetW_LUR_estimates_HALVES + stat_ellipse()


# LUR-modelled mecA
PCoA.plot.mecA_LUR_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "mecA_LUR_estimates", shape="mecA_LUR_estimates") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by mecA exposure halves (LUR-modelled)") +
  labs(legend="mecA (LUR-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = mecA_LUR_estimates))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.mecA_LUR_estimates_HALVES
# Add ellipses 
PCoA.plot.mecA_LUR_estimates_HALVES + stat_ellipse()

# RF-modelled E. coli
PCoA.plot.E.coli_RF_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "E.coli_RF_predictions", shape="E.coli_RF_predictions") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by E. coli exposure halves (RF-modelled)") +
  labs(legend="E. coli (RF-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = E.coli_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.E.coli_RF_estimates_HALVES
# Add ellipses 
PCoA.plot.E.coli_RF_estimates_HALVES + stat_ellipse()

# RF-modelled Staph
PCoA.plot.Staph_RF_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "Staph_RF_predictions", shape="Staph_RF_predictions") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by Staph exposure halves (RF-modelled)") +
  labs(legend="Staph (RF-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = Staph_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.Staph_RF_estimates_HALVES
# Add ellipses 
PCoA.plot.Staph_RF_estimates_HALVES + stat_ellipse()

# RF-modelled tetW
PCoA.plot.tetW_RF_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "tetW_RF_predictions", shape="tetW_RF_predictions") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by tetW exposure halves (RF-modelled)") +
  labs(legend="tetW (RF-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = tetW_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.tetW_RF_estimates_HALVES
# Add ellipses 
PCoA.plot.tetW_RF_estimates_HALVES + stat_ellipse()


# RF-modelled mecA
PCoA.plot.mecA_RF_estimates_HALVES <- plot_ordination( ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES, ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES.PCoA, color = "mecA_RF_predictions", shape="mecA_RF_predictions") +
  ggtitle("BC PCoA (fully corrected and rarefied ARG counts, 90% identity clustered) - \ncoloured by mecA exposure halves (RF-modelled)") +
  labs(legend="mecA (RF-modelled) exposure halves")+
  geom_point(size =5) +
  geom_text( aes( label=row.names(ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data),hjust=-0.3, vjust=-0.5 ) ) +
  theme(plot.title = element_text(size = 13))+ # adjusting size of title text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10)) + # adjusting size of axis text
  theme(legend.text=element_text(size=8),
        legend.title = element_text(size=8))+ # adjusting size of legend text
  stat_ellipse(geom = "polygon", alpha = 1/6, aes(fill = mecA_RF_predictions))# adds ellipses to the PCoA, fills ellipses with colour according to copdcaco status, colour transparency=1/4 of strength 
PCoA.plot.mecA_RF_estimates_HALVES
# Add ellipses 
PCoA.plot.mecA_RF_estimates_HALVES + stat_ellipse()

```
## Beta diversity tests
```{r}
# There are two tests that are widely used in beta diversity analyses: betadisper and adonis. 
# Betadisper tests whether two or more groups are homogeneously dispersed in relation to their species in studied samples (it is a multivariate analogue of Levene's test for homogeneity of variances). This test can be done to see if one group has more compositional variance than another. Moreover, homogeneity of dispersion among groups is very advisable to have if you want to test if two or more groups have different compositions, which is tested by adonis. So firstly I will perform betadisper: then move onto adonis
# Use betadisper to assess homogeneity of group dispersions - it first calculates the average distance of group members to the group centroid in multivariate space (generated by a distance matrix). Then, an ANOVA is done to test if the dispersions (variances) of groups are different.
#Extract abundance matrix from phyloseq object
ARGclusters.for.beta.div.LUR.RF.estimates <- as(otu_table(ARGcluster.aggl.noblanks.LUR.RF.estimates), "matrix")
# transform into a data frame
ARG.cluster.LUR.RF.df <- as.data.frame(ARGclusters.for.beta.div.LUR.RF.estimates)
ARG.cluster.LUR.RF.df
ARG.cluster.LUR.RF.df <- subset(ARG.cluster.LUR.RF.df, select = -copdcaco)

# compute BC distances between samples
BC.distance.LUR.RF <- vegdist(ARG.cluster.LUR.RF.df, method =  "bray")

# add columns to the df now
ARG.cluster.LUR.RF.df$E.coli_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_LUR_estimates
ARG.cluster.LUR.RF.df$Staph_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_LUR_estimates
ARG.cluster.LUR.RF.df$tetW_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_LUR_estimates
ARG.cluster.LUR.RF.df$mecA_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_LUR_estimates
ARG.cluster.LUR.RF.df$E.coli_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$E.coli_RF_predictions
ARG.cluster.LUR.RF.df$Staph_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$Staph_RF_predictions
ARG.cluster.LUR.RF.df$tetW_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$tetW_RF_predictions
ARG.cluster.LUR.RF.df$mecA_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.QUANT@sam_data$mecA_RF_predictions

# E.coli_LUR_estimates 
# Betadisper
Betadisper.ARGcluster.E.coli_LUR_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$E.coli_LUR_estimates)
Betadisper.ARGcluster.E.coli_LUR_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.E.coli_LUR_estimates) # p-value = 0.3734 - group dispersions are homogenous
plot(Betadisper.ARGcluster.E.coli_LUR_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$E.coli_LUR_estimates, permutations = 999)# p-value = 0.292 - no significant differences in group centroids-  We can conclude that our groups (quartiles of e. coli (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# Staph_LUR_estimates
# Betadisper
Betadisper.ARGcluster.Staph_LUR_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$Staph_LUR_estimates)
Betadisper.ARGcluster.Staph_LUR_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.Staph_LUR_estimates) # p-value = 0.8389 - group dispersions are homogenous
plot(Betadisper.ARGcluster.Staph_LUR_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$Staph_LUR_estimates, permutations = 999)# p-value = 0.42 - no significant differences in group centroids-  We can conclude that our groups (quartiles of Staph (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# tetW_LUR_estimates
# Betadisper
Betadisper.ARGcluster.tetW_LUR_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$tetW_LUR_estimates)
Betadisper.ARGcluster.tetW_LUR_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.tetW_LUR_estimates) # p-value = 0.78 - group dispersions are homogenous
plot(Betadisper.ARGcluster.tetW_LUR_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$tetW_LUR_estimates, permutations = 999)# p-value = 0.194 - no significant differences in group centroids-  We can conclude that our groups (quartiles of tetW (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# mecA_LUR_estimates
# Betadisper
Betadisper.ARGcluster.mecA_LUR_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$mecA_LUR_estimates)
Betadisper.ARGcluster.mecA_LUR_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.mecA_LUR_estimates) # p-value = 0.8345 - group dispersions are homogenous
plot(Betadisper.ARGcluster.mecA_LUR_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$mecA_LUR_estimates, permutations = 999)# p-value = 0.305 - no significant differences in group centroids-  We can conclude that our groups (quartiles of mecA (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# E.coli_RF_predictions 
# Betadisper
Betadisper.ARGcluster.E.coli_RF_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$E.coli_RF_predictions)
Betadisper.ARGcluster.E.coli_RF_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.E.coli_RF_estimates) # p-value = 0.5236 - group dispersions are homogenous
plot(Betadisper.ARGcluster.E.coli_RF_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$E.coli_RF_predictions, permutations = 999)# p-value = 0.072  - borderline no significant differences in group centroids-  We can conclude that our groups (quartiles of e. coli (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# Staph_RF_predictions
# Betadisper
Betadisper.ARGcluster.Staph_RF_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$Staph_RF_predictions)
Betadisper.ARGcluster.Staph_RF_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.Staph_RF_estimates) # p-value = 0.7748 - group dispersions are homogenous
plot(Betadisper.ARGcluster.Staph_RF_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$Staph_RF_predictions, permutations = 999)# p-value = 0.775 - no significant differences in group centroids-  We can conclude that our groups (quartiles of Staph (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# tetW_RF_predictions
# Betadisper
Betadisper.ARGcluster.tetW_RF_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$tetW_RF_predictions)
Betadisper.ARGcluster.tetW_RF_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.tetW_RF_estimates) # p-value = 0.9639 - group dispersions are homogenous
plot(Betadisper.ARGcluster.tetW_RF_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$tetW_RF_predictions, permutations = 999)# p-value = 0.321 - no significant differences in group centroids-  We can conclude that our groups (quartiles of tetW (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# mecA_RF_predictions
# Betadisper
Betadisper.ARGcluster.mecA_RF_estimates <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df$mecA_RF_predictions)
Betadisper.ARGcluster.mecA_RF_estimates
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.mecA_RF_estimates) # p-value = 0.6946 - group dispersions are homogenous
plot(Betadisper.ARGcluster.mecA_RF_estimates) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df$mecA_LUR_estimates, permutations = 999)# p-value = 0.291 - no significant differences in group centroids-  We can conclude that our groups (quartiles of mecA (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)


# High vs low exposed
ARGclusters.for.beta.div.LUR.RF.estimates <- as(otu_table(ARGcluster.aggl.noblanks.LUR.RF.estimates), "matrix")
# transform into a data frame
ARG.cluster.LUR.RF.df_HALVES <- as.data.frame(ARGclusters.for.beta.div.LUR.RF.estimates)
ARG.cluster.LUR.RF.df_HALVES

# compute BC distances between samples
BC.distance.LUR.RF <- vegdist(ARG.cluster.LUR.RF.df_HALVES, method =  "bray")

# add columns to the df now
# add columns to the df now
ARG.cluster.LUR.RF.df_HALVES$E.coli_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_LUR_estimates
ARG.cluster.LUR.RF.df_HALVES$Staph_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_LUR_estimates
ARG.cluster.LUR.RF.df_HALVES$tetW_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_LUR_estimates
ARG.cluster.LUR.RF.df_HALVES$mecA_LUR_estimates <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_LUR_estimates
ARG.cluster.LUR.RF.df_HALVES$E.coli_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$E.coli_RF_predictions
ARG.cluster.LUR.RF.df_HALVES$Staph_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$Staph_RF_predictions
ARG.cluster.LUR.RF.df_HALVES$tetW_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$tetW_RF_predictions
ARG.cluster.LUR.RF.df_HALVES$mecA_RF_predictions <- ARGcluster.aggl.noblanks.LUR.RF.estimates.HALVES@sam_data$mecA_RF_predictions

# E.coli_LUR_estimates 
# Betadisper
Betadisper.ARGcluster.E.coli_LUR_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$E.coli_LUR_estimates)
Betadisper.ARGcluster.E.coli_LUR_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.E.coli_LUR_estimates_HALVES) # p-value = 0.3734 - group dispersions are homogenous
plot(Betadisper.ARGcluster.E.coli_LUR_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$E.coli_LUR_estimates, permutations = 999)# p-value = 0.292 - no significant differences in group centroids-  We can conclude that our groups (halves of e. coli (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# Staph_LUR_estimates
# Betadisper
Betadisper.ARGcluster.Staph_LUR_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$Staph_LUR_estimates)
Betadisper.ARGcluster.Staph_LUR_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.Staph_LUR_estimates_HALVES) # p-value = 0.8389 - group dispersions are homogenous
plot(Betadisper.ARGcluster.Staph_LUR_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$Staph_LUR_estimates, permutations = 999)# p-value = 0.42 - no significant differences in group centroids-  We can conclude that our groups (halves of Staph (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# tetW_LUR_estimates
# Betadisper
Betadisper.ARGcluster.tetW_LUR_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$tetW_LUR_estimates)
Betadisper.ARGcluster.tetW_LUR_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.tetW_LUR_estimates_HALVES) # p-value = 0.78 - group dispersions are homogenous
plot(Betadisper.ARGcluster.tetW_LUR_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$tetW_LUR_estimates, permutations = 999)# p-value = 0.194 - no significant differences in group centroids-  We can conclude that our groups (halves of tetW (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# mecA_LUR_estimates
# Betadisper
Betadisper.ARGcluster.mecA_LUR_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$mecA_LUR_estimates)
Betadisper.ARGcluster.mecA_LUR_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.mecA_LUR_estimates_HALVES) # p-value = 0.8345 - group dispersions are homogenous
plot(Betadisper.ARGcluster.mecA_LUR_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$mecA_LUR_estimates, permutations = 999)# p-value = 0.305 - no significant differences in group centroids-  We can conclude that our groups (halves of mecA (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# E.coli_RF_predictions 
# Betadisper
Betadisper.ARGcluster.E.coli_RF_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$E.coli_RF_predictions)
Betadisper.ARGcluster.E.coli_RF_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.E.coli_RF_estimates_HALVES) # p-value = 0.5738 - group dispersions are homogenous
plot(Betadisper.ARGcluster.E.coli_RF_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$E.coli_RF_predictions, permutations = 999)# p-value = 0.945  - borderline no significant differences in group centroids-  We can conclude that our groups (halves of e. coli (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# Staph_RF_predictions
# Betadisper
Betadisper.ARGcluster.Staph_RF_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$Staph_RF_predictions)
Betadisper.ARGcluster.Staph_RF_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.Staph_RF_estimates_HALVES) # p-value = 0.4468 - group dispersions are homogenous
plot(Betadisper.ARGcluster.Staph_RF_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$Staph_RF_predictions, permutations = 999)# p-value = 0.696 - no significant differences in group centroids-  We can conclude that our groups (halves of Staph (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# tetW_RF_predictions
# Betadisper
Betadisper.ARGcluster.tetW_RF_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$tetW_RF_predictions)
Betadisper.ARGcluster.tetW_RF_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.tetW_RF_estimates_HALVES) # p-value = 0.8652 - group dispersions are homogenous
plot(Betadisper.ARGcluster.tetW_RF_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
set.seed(123)
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$tetW_RF_predictions, permutations = 999)# p-value = 0.875 - no significant differences in group centroids-  We can conclude that our groups (halves of tetW (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# mecA_RF_predictions
# Betadisper
Betadisper.ARGcluster.mecA_RF_estimates_HALVES <- betadisper(BC.distance.LUR.RF, ARG.cluster.LUR.RF.df_HALVES$mecA_RF_predictions)
Betadisper.ARGcluster.mecA_RF_estimates_HALVES
# Perform an anova using the group dispersions to check for homogeneity of the group dispersions
anova(Betadisper.ARGcluster.mecA_RF_estimates_HALVES) # p-value = 0.5117 - group dispersions are homogenous
plot(Betadisper.ARGcluster.mecA_RF_estimates_HALVES) # Here we see that group dispersions (distances from centroids) are very similar, but also that compositions seem to be very similar too. Let's go to adonis to test whether these compositions are different or not. 
# Use adonis to assess compositional dissimilarity - The adonis2() function in the vegan package is an analysis of variance using distance matrices 
adonis2(BC.distance.LUR.RF~ ARG.cluster.LUR.RF.df_HALVES$mecA_LUR_estimates, permutations = 999)# p-value - no significant differences in group centroids-  We can conclude that our groups (halves of tetW (LUR-modelled) exposure present homogeneity among group dispersions (compositions vary similarly) and also they have very similar compositions (adonis not significant)

# None significant with data cut in halves either

```
# Differential abundance analysis
```{r}
# Since the DESeq2 function requires count data which has not been corrected for gene length, I need to create a new ps object with only corrections for volume input and qPCR bacterial count
# This ps object is just corrected for volume inputs
merged.rar3 <- readRDS("Input_files//merged.rar3.rds")
metafile  <- "Input_files//VGOCOPD_metadata_completed_20210429alx_correctFormulaColumnTU.xlsx.tab"
argmappingfile  <- "Input_files//02e_TotalResfinderMapped_v3.tab"

metadata <- read.csv( metafile, header=TRUE, sep="\t", row.names=1 )
metadata
ARG.long <- read.csv( argmappingfile, header=TRUE, sep="\t")
head(ARG.long)

# We now want to correct for qPCR bacterial counts, but we don't want to correct for gene length. 
# create a list of sample ID and associated 16S qPCR count
qPCRcounts <- data.frame("SampleID"= unique(ARG.long$SampleName), "qPCR16S"= metadata$qPCR_16S_ngml)
rownames(qPCRcounts) <- NULL
qPCRcounts <- qPCRcounts %>% column_to_rownames("SampleID")

# convert otu values directly by matrix manipulation in the ps object using qPCRcounts data frame 
ps.for.DA <- merged.rar3
ps.for.DA@otu_table@.Data <- ps.for.DA@otu_table@.Data / qPCRcounts [ 1:73 ,]

# checks
ps.for.DA
head(taxa_names(ps.for.DA))
ps.for.DA@otu_table@.Data

# There was an error in the choice and labelling of 1 control sample and we ended up with the same control sample being used for 2 case samples. It was mislabelled as '13674' hence was thought to be a different sample to '13764' which was already included in the dataset. Therefore we must remoce '13674' from the dataset. 
ps.for.DA <- prune_samples(sample_names(ps.for.DA) != "13674", ps.for.DA) 
ps.for.DA
# Final PS object therefore now has 72 samples in total (35 cases, 34 controls, 3 blanks)

# Agglomerate at 90% cluster level
# Using the functions created by AB, I will now agglomerate the data to AMRcluster level - i.e. merge ARGs which are in the same ARGcluster (90% identity level)  
# Clustering of ARGs at the 90% identity level is classified as 'ARGCluster' in the tax data of the Final.ps object - agglomerate at this level i.e. create a new ps object with cluster 90 as default. Automatic default is the ARG level but this may not be very accurate therefore best to use cluster90 level (ARGCluster in ps object). 

# Tax_glom2 function as created by AB - save this in the global environment for later use
tax_glom2 <- function(physeq, taxrank=rank_names(physeq)[1],
                     NArm=TRUE, bad_empty=c(NA, "", " ", "\t")){
  #### This part is identical to phyloseq's tax_glom
  # Error if tax_table slot is empty
  if( is.null(access(physeq, "tax_table")) ){
    stop("The tax_glom2() function requires that physeq contain a taxonomyTable")
  }
  # Error if bad taxrank
  if( !taxrank[1] %in% rank_names(physeq) ){
    stop("Bad taxrank argument. Must be among the values of rank_names(physeq)")
  }
  # Make a vector from the taxonomic data.
  CN  <- which( rank_names(physeq) %in% taxrank[1] )
  tax <- as(access(physeq, "tax_table"), "matrix")[, CN]
  # if NArm is TRUE, remove the empty, white-space, NA values from
  if( NArm ){
    keep_species <- names(tax)[ !(tax %in% bad_empty) ]
    physeq <- prune_taxa(keep_species, physeq)
  }
  # Concatenate data up to the taxrank column, use this for agglomeration
  tax <- as(access(physeq, "tax_table"), "matrix")[, 1:CN, drop=FALSE]
  tax <- apply(tax, 1, function(i){paste(i, sep=";_;", collapse=";_;")})
  #### **Speedyseq changes start here**
  ## Make the new OTU table
  # Work with taxa as rows
  if (!taxa_are_rows(physeq)) {
    physeq <- phyloseq::t(physeq)
    # Note that we need to flip back to samples as rows at the end
    needs_flip <- TRUE
  } else {
    needs_flip <- FALSE
  }
  # Starting point is a tibble with rows as taxa, to be able to combine taxa
  # with the dplyr::summarize_*() functions
  otu <- otu_table(physeq)
  tb <- otu %>%
    as("matrix") %>%
    tibble::as_tibble(rownames = "OTU")
  # We want to name each new taxon (group of merged OTUs) by its "archetype",
  # the most abundant OTU in the group
  tb <- tb %>%
    tibble::add_column(Tax = tax, Sum = taxa_sums(physeq)) %>%
    dplyr::group_by(Tax)
  # Name new taxa by the most abundant OTU; pick the first OTU in case of
  # ties (to be consistent with phyloseq)
  new_taxa_names <- tb %>%
    dplyr::top_n(1, Sum) %>%
    dplyr::slice(1) %>%
    dplyr::select(Tax, OTU)
  # Sum abundances and rename taxa
  tb0 <- tb %>%
    dplyr::summarize_at(dplyr::vars(sample_names(physeq)), sum) %>%
    dplyr::left_join(new_taxa_names, by = "Tax") %>%
    dplyr::select(OTU, dplyr::everything(), -Tax)
  # Put back into phyloseq form
  mat <- tb0 %>%
    dplyr::select(-OTU) %>%
    as("matrix")
  rownames(mat) <- tb0$OTU
  otu0 <- otu_table(mat, taxa_are_rows = TRUE)
  ## Make the new phyloseq object
  # Replacing the original otu_table with the new, smaller table will
  # automatically prune the taxonomy, tree, and refseq to the smaller set of
  # archetypal otus
  otu_table(physeq) <- otu0
  # "Empty" the taxonomy values to the right of the rank, using
  # NA_character_.
  if (CN < length(rank_names(physeq))) {
    bad_ranks <- seq(CN + 1, length(rank_names(physeq)))
    tax_table(physeq)[, bad_ranks] <- NA_character_
  }
  ## Return.
  if (needs_flip) {
    physeq <- phyloseq::t(physeq)
  }
  return(physeq)
}

# Use function tax_glom2 - 6 is the ARGCluster level in the tax_table of Final.ps object. This creates a new ps object with ARGcluster as default 
ps.for.DA.aggl <- tax_glom2(ps.for.DA, taxrank=rank_names(ps.for.DA)[6], NArm=TRUE)
taxa_names(ps.for.DA.aggl)

# How many taxa before/after agglomeration?
ntaxa(ps.for.DA); ntaxa(ps.for.DA.aggl)

# How many taxa before/after agglomeration?
ntaxa(ps.for.DA); ntaxa(ps.for.DA.aggl) # 85 ARGClusters vs 233 ARGs 

# Now remove the blanks from this ps object
sam.data.noblanks <- subset(sample_data(ps.for.DA.aggl), !(row.names(sample_data(ps.for.DA.aggl)) %in% c("veldbl16", "veldbl3", "veldbl5")))
# Remove corresponding data from the phyloseq object
ps.for.DA.aggl.noblanks <- prune_samples(sample_names(sam.data.noblanks), ps.for.DA.aggl)

# Now add new sample data with exposure estimates from modelling
ps.for.DA.aggl.noblanks.expmodels <- ps.for.DA.aggl.noblanks
sam.data.new <- as.data.frame(sample_data(LUR_RF_residential_predictions))
sample_data(ps.for.DA.aggl.noblanks.expmodels) <- sam.data.new
ps.for.DA.aggl.noblanks.expmodels@sam_data
taxa_names(ps.for.DA.aggl.noblanks.expmodels)

# Filter- 0.1% relative abundance, 15% prevalent
# Create prevalence-abundance filter
# 0.1% abundant, 15% prevalent: Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
pres_abund_filter_deseq <- function(ps.for.DA.aggl.noblanks.expmodels, pres=10.35, abund=0.001) { # Subramanian filter, keep taxa that are more than 0.1% (proportion = 0.001) abundant in more than 15% of samples (15% of 69= 10.35)
filter_taxa(ps.for.DA.aggl.noblanks.expmodels, function(x) sum(x >= abund)>=pres, TRUE) }
# apply filter
ps.for.DA.aggl.noblanks.expmodels.filtered <- transform_sample_counts(ps.for.DA.aggl.noblanks.expmodels, function(x) x/sum(x) *100 ) %>% pres_abund_filter_deseq()

taxa_names(ps.for.DA.aggl.noblanks.expmodels.filtered)
# The apostrophes in the taxa names got lost in the agglomeration step and also the 'taxa_names' are not the ARGcluster names. The lowest level is the ARG cluster (the lower ranks are NA). However, the taxon name is the "wrong" accession name. 
# I rename the taxa based on the ARG cluster to which it corresponds.
taxa_names_ARGCluster <- as.data.frame(ps.for.DA.aggl.noblanks.expmodels.filtered@tax_table)[, "ARGCluster"]
colnames(ps.for.DA.aggl.noblanks.expmodels.filtered@otu_table) <- taxa_names_to_use
# Verify the changes
taxa_names(otu_table(ps.for.DA.aggl.noblanks.expmodels.filtered))

# This is the final ps object to be used for DA analysis. It has been volume corrected, corrected for qPCR counts, agglomerated at 90% identity level and filtered so that taxa which are more than 0.1% abundant in more than 15% of samples are kept. 
ps.for.DA.aggl.noblanks.expmodels.filtered

# Check parts of the ps object to ensure all ok
ps.for.DA.aggl.noblanks.expmodels.filtered@otu_table # 30 taxa (agglomerated and filtered and named by the ARGCluster name)
ps.for.DA.aggl.noblanks.expmodels.filtered@sam_data # 69 sammples (no blanks - 35 copd cases and 34 controls)
ps.for.DA.aggl.noblanks.expmodels.filtered@tax_table # Contains information on 30 taxa

# Save this ps object
saveRDS(ps.for.DA.aggl.noblanks.expmodels.filtered, "Output_files//ps.for.DA.aggl.noblanks.expmodels.filtered.rds")
taxa_names(ps.for.DA.aggl.noblanks.expmodels.filtered)


# Determining exposure effects on ARG expression 
# The differential abundance (DA) analysis using DESeq2 aims to identify features (such as taxa) that show statistically significant differences in their abundance across different levels of the continuous predictor variables (the modelled exposures). The analysis provides insight into how the abundance of these features varies in response to changes in the continuous variable.
# All estimates are continuous variables
# Now ready to run the deseq2 analysis using the phyloseq_to_deseq2 function
# Rename ps for simplicity
Deseq_ps <- ps.for.DA.aggl.noblanks.expmodels.filtered
# E.coli LUR modelled concentrations 
# Convert phyloseq data to DESeq2 dataset object
deseq2.ecoliLUR <- phyloseq_to_deseq2(Deseq_ps,~E.coli_LUR_estimates)
# Run DESeq function 
deseq2.ecoliLUR <- DESeq(deseq2.ecoliLUR)
deseq2.ecoliLUR.results<- results(deseq2.ecoliLUR)
deseq2.ecoliLUR.results
# The log2 fold change represents the change in taxa abundance associated with a one-unit increase in E.coli_LUR_estimates values. If LFC is positive, it means that with a 1 unit increase in E.coli_LUR_estimates concentration, the abundance increases on a log2 scale. If negative then a 1 unit change is associated with decreases in abundance. 
# summary of differential gene expression
summary(deseq2.ecoliLUR.results)
# 23 out of 30 taxa have 'nonzero total read count' - this means that for 7 taxa the count data is extremely low whcih affects the abilit o perform meaningful statistical analysis. 
# Adjusted p-value < 0.1: This indicates the number and percentage of features for which the adjusted p-value (padj) is less than 0.1. These are features that are potentially showing some level of association with the predictor variable (E.coli_LUR_estimates). The adjusted p-value takes into account multiple testing correction to control the false discovery rate.
# LFC > 0 (up): 0, 0%: This shows that none of the features are identified as having a positive log2 fold change (upregulated) at a significance level where the adjusted p-value is less than 0.1.
# LFC < 0 (down): 0, 0% Similarly, none of the features are identified as having a negative log2 fold change (downregulated) at a significance level where the adjusted p-value is less than 0.1.
# outliers [1]: 0, 0% This is indicating that no features are identified as outliers based on the Cook's distance metric.
# Among the 30 ARGs analysed, none are showing significant differential abundance based on the adjusted p-values and log2 fold changes in relation to the continuous predictor variable E.coli_LUR_estimates.
sum(deseq2.ecoliLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Staph LUR modelled concentrations 
deseq2.staphLUR <- phyloseq_to_deseq2(Deseq_ps,~Staph_LUR_estimates)
deseq2.staphLUR <- DESeq(deseq2.staphLUR)
deseq2.staphLUR.results<- results(deseq2.staphLUR)
deseq2.staphLUR.results
sum(deseq2.staphLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# tetW LUR modelled concentrations 
deseq2.tetWLUR <- phyloseq_to_deseq2(Deseq_ps,~tetW_LUR_estimates)
deseq2.tetWLUR <- DESeq(deseq2.tetWLUR)
deseq2.tetWLUR.results<- results(deseq2.tetWLUR)
deseq2.tetWLUR.results
sum(deseq2.tetWLUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# mecA LUR modelled concentrations 
deseq2.mecALUR <- phyloseq_to_deseq2(Deseq_ps,~ mecA_LUR_estimates)
deseq2.mecALUR <- DESeq(deseq2.mecALUR)
deseq2.mecALUR.results<- results(deseq2.mecALUR)
deseq2.mecALUR.results
sum(deseq2.mecALUR.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# E.coli RF modelled concentrations
deseq2.ecoliRF <- phyloseq_to_deseq2(Deseq_ps,~ E.coli_RF_predictions)
deseq2.ecoliRF <- DESeq(deseq2.ecoliRF)
deseq2.ecoliRF.results<- results(deseq2.ecoliRF)
deseq2.ecoliRF.results
sum(deseq2.ecoliRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Staph RF modelled concentrations 
deseq2.staphRF <- phyloseq_to_deseq2(Deseq_ps,~ Staph_RF_predictions)
deseq2.staphRF <- DESeq(deseq2.staphRF)
deseq2.staphRF.results<- results(deseq2.staphRF)
deseq2.staphRF.results
sum(deseq2.staphRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# tetW RF modelled concentrations 
deseq2.tetWRF <- phyloseq_to_deseq2(Deseq_ps,~ tetW_RF_predictions)
deseq2.tetWRF <- DESeq(deseq2.tetWRF)
deseq2.tetWRF.results<- results(deseq2.tetWRF)
deseq2.tetWRF.results
sum(deseq2.tetWRF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# mecA RF modelled concentrations 
deseq2.mecARF <- phyloseq_to_deseq2(Deseq_ps,~ tetW_RF_predictions)
deseq2.mecARF <- DESeq(deseq2.mecARF)
deseq2.mecARF.results<- results(deseq2.mecARF)
deseq2.mecARF.results
sum(deseq2.mecARF.results$padj < 0.1, na.rm=TRUE) # 0 ARG clusters have p-value <0.1

# Save results tables as excel files 
write.csv(deseq2.ecoliLUR.results, "Output_files//DESeq_results//deseq2.ecoliLUR.results.csv")
write.csv(deseq2.staphLUR.results, "Output_files//DESeq_results//deseq2.staphLUR.results.csv")
write.csv(deseq2.tetWLUR.results, "Output_files//DESeq_results//deseq2.tetWLUR.results.csv")
write.csv(deseq2.mecALUR.results, "Output_files//DESeq_results//deseq2.mecALUR.results.csv")
write.csv(deseq2.ecoliRF.results, "Output_files//DESeq_results//deseq2.ecoliRF.results.csv")
write.csv(deseq2.staphRF.results, "Output_files//DESeq_results//deseq2.staphRF.results.csv")
write.csv(deseq2.tetWRF.results, "Output_files//DESeq_results//deseq2.tetWRF.results.csv")
write.csv(deseq2.mecARF.results, "Output_files//DESeq_results//deseq2.mecARF.results.csv")

# Visualising results from DA analysis
# Create the volcano plot with log-scaled y-axis
volcano_plot_ecoliLUR <- ggplot(ecoliLUR_df, aes(x = log2FoldChange, y = -log10(padj))) +
  geom_point(aes(color = ifelse(padj < 0.1, "Significant", "Non-Significant")), alpha = 0.6) +
  labs(title = "Volcano Plot",
       x = "log2 Fold Change",
       y = "-log10(Adjusted p-value)") +
  theme_minimal() +
  geom_hline(yintercept = -log10(0.1), linetype = "dotted", color = "grey") +
  scale_color_manual(values = c("Significant" = "black", "Non-Significant" = "grey")) +
  scale_y_continuous(trans = "log10")  # Use log10 scale for y-axis

# Print the plot
print(volcano_plot_ecoliLUR)

# These plots are not very informative since there are no significantly different ARGs, will just present tables in supplement. 

```




